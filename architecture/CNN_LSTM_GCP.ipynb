{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "W_rZdBudC-DT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import time\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kK6zkqUBKPYE"
   },
   "outputs": [],
   "source": [
    "class ExpandedCnnLSTM(nn.Module):\n",
    "  \n",
    "  def __init__(self, resnet_model, n_channels, output_size, hidden_dim, n_lstm_layers, drop_prob=0.5, debug=False):\n",
    "\n",
    "    super(ExpandedCnnLSTM, self).__init__()\n",
    "\n",
    "    self.output_size = output_size\n",
    "    self.n_lstm_layers = n_lstm_layers\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.n_channels = n_channels\n",
    "          \n",
    "    model = torch.hub.load('pytorch/vision:v0.6.0', resnet_model, pretrained=True)\n",
    "    out_channels = model.conv1.in_channels\n",
    "    kernel_size = model.conv1.kernel_size\n",
    "    stride = model.conv1.stride\n",
    "    padding = model.conv1.padding\n",
    "    self.convPadd = nn.Conv2d(n_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    \n",
    "    self.embeding_dim = model.fc.in_features\n",
    "    self.cnn = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    if debug:\n",
    "      print(model.eval())\n",
    "      print(self.cnn[0].in_channels)\n",
    "    \n",
    "\n",
    "    self.lstm = nn.LSTM(self.embeding_dim, hidden_dim, n_lstm_layers, dropout=drop_prob, batch_first=True)\n",
    "    self.dropout = nn.Dropout(drop_prob)\n",
    "    self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    n_frames = x.size(1)\n",
    "\n",
    "    features = torch.zeros((batch_size, n_frames, self.embeding_dim))\n",
    "\n",
    "    for i in range(n_frames):\n",
    "      padded = self.convPadd(x[:,i,:])\n",
    "      features[:,i,:] = self.cnn(padded).squeeze()\n",
    "\n",
    "    lstm_out, hidden = self.lstm(features.to(device))\n",
    "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "    out = self.dropout(lstm_out)\n",
    "    out = self.fc(out)\n",
    "    out = self.sigmoid(out)\n",
    "    \n",
    "    out = out.view(batch_size, -1)\n",
    "    out = out[:,-1]\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_lstm_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_lstm_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8iEpHIEdisnS",
    "outputId": "069d1b18-c83c-4136-f936-aa940990fded"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /home/jupyter/.cache/torch/hub/v0.6.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/jupyter/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0fdf76e4094606908dc73510cf72d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#cl_model = CnnLSTM(4, 1, 512, 2)\n",
    "cl_model = ExpandedCnnLSTM('resnet18', 4, 1, 512, 2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_path = '/home/jupyter/data-step/processed_data/positive/dataset/'\n",
    "negative_path = '/home/jupyter/data-step/processed_data/negative/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_path_norm = '/home/jupyter/data-step/normalized_data/positive/dataset/'\n",
    "negative_path_norm = '/home/jupyter/data-step/normalized_data/negative/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znEhF4y2f7da",
    "outputId": "c2ee523b-b596-4a68-e94a-62a01ab89084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556\n",
      "1184\n"
     ]
    }
   ],
   "source": [
    "positive_files = [positive_path_norm + f for f in listdir(positive_path_norm)]\n",
    "y_p = np.ones((len(positive_files)))\n",
    "print(len(positive_files))\n",
    "\n",
    "negative_files = [negative_path_norm + f for f in listdir(negative_path_norm)]\n",
    "y_n = np.zeros((len(negative_files)))\n",
    "print(len(negative_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2740 (2740,)\n"
     ]
    }
   ],
   "source": [
    "total_files = positive_files + negative_files\n",
    "\n",
    "y_tot = np.append(y_p, y_n)\n",
    "\n",
    "print(len(total_files), y_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjpqKWgw4zg5",
    "outputId": "353995cd-1ed1-40df-ad8b-6af79be5a1f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9588c0928295414b91aad7c0e9a9b901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d7f82accc743608bc165afa823f71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def channel_metrics(data):\n",
    "    n_channels = len(data[0,0, :])\n",
    "    #print(\"num channels: \", n_channels)\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for i in range(n_channels):\n",
    "            means.append(np.mean(data[:, :, i, :, :]))\n",
    "            stds.append(np.std(data[:, :, i, :, :]))\n",
    "    #print(means, stds)\n",
    "    return means, stds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def total_metrics(files):\n",
    "    means = []\n",
    "    stds = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in tqdm(files):\n",
    "        #print(count, end='\\r')\n",
    "        data = torch.load(f)\n",
    "        #print(data.shape)\n",
    "        mean, std = channel_metrics(data.numpy())\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "        count += 1\n",
    "        \n",
    "    return means, stds\n",
    "\n",
    "means_p, stds_p = total_metrics(positive_files)\n",
    "means_n, stds_n = total_metrics(negative_files)\n",
    "#means, stds = total_metrics(total_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#means_np = np.array(means)\n",
    "#print(means_np.shape)\n",
    "\n",
    "#stds_np = np.array(stds)\n",
    "#print(stds_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 16)\n",
      "(200, 16)\n"
     ]
    }
   ],
   "source": [
    "means_np = np.append(np.array(means_p),np.array(means_n), axis=0)\n",
    "print(means_np.shape)\n",
    "\n",
    "stds_np = np. append(np.array(stds_p), np.array(stds_n), axis=0)\n",
    "print(stds_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,) (16,)\n",
      "[7.6738763e+00 5.6706287e+02 2.9339214e+01 2.3591624e+02 3.9848883e+00\n",
      " 4.5335560e+00 1.3335173e+04 1.3598129e+04 1.3136590e+04 7.3626434e+01\n",
      " 3.6517732e+03 1.7995854e+03 2.3275046e+03 1.2996396e+03 6.5904746e+03\n",
      " 4.3150551e+01] [ 0.08378748  3.460925    0.4906571   5.4532857   0.16992834  0.20344873\n",
      " 65.78737    67.112564   64.78857     2.0113964  20.092962    4.5374813\n",
      "  4.6400423   4.549636    8.566295    0.33656853]\n"
     ]
    }
   ],
   "source": [
    "norm_means = np.mean(means_np, axis=0)\n",
    "norm_stds = np.sqrt(np.sum((np.array(stds_np)**2), axis=0))/len(total_files)\n",
    "\n",
    "print(norm_means.shape, norm_stds.shape)\n",
    "print(norm_means, norm_stds)\n",
    "np.save(\"/home/jupyter/means.npy\", norm_means)\n",
    "np.save(\"/home/jupyter/stds.npy\", norm_stds)\n",
    "\n",
    "norm_means = np.load(\"/home/jupyter/means.npy\")\n",
    "norm_stds = np.load(\"/home/jupyter/stds.npy\")\n",
    "\n",
    "#stds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "                                transforms.Normalize(mean=norm_means, std=norm_stds)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IN15Tc68XwDH"
   },
   "outputs": [],
   "source": [
    "class LandslideDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, dirs, y):\n",
    "\n",
    "        self.dirs = sorted(dirs) \n",
    "        self.l = len(self.dirs)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.dirs)*5   # REVISAR ESTO\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return torch.load(self.dirs[int(idx/self.l)])[idx%self.l], self.y[int(idx/self.l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/data-step/normalized_data/positive/dataset/divided_part_1600_3.pt\n"
     ]
    }
   ],
   "source": [
    "#total_ds = LandslideDataset(total_files, y_tot)\n",
    "random.shuffle(positive_files)\n",
    "random.shuffle(negative_files)\n",
    "\n",
    "print(positive_files[0])\n",
    "\n",
    "pos_cut = int(0.9*len(positive_files))\n",
    "neg_cut = int(0.9*len(negative_files))\n",
    "\n",
    "train_files = positive_files[:pos_cut] + negative_files[:neg_cut]\n",
    "train_labels = np.append(np.ones(pos_cut), np.zeros(neg_cut))\n",
    "                         \n",
    "val_files = positive_files[pos_cut:] + negative_files[neg_cut:]\n",
    "val_labels = np.append(np.ones(len(positive_files) - pos_cut), np.zeros(len(negative_files) - neg_cut))\n",
    "\n",
    "# Datasets\n",
    "                         \n",
    "train_ds = LandslideDataset(train_files, train_labels)\n",
    "val_ds = LandslideDataset(val_files, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "\n",
    "train_dl = DataLoader(train_ds, num_workers=16)\n",
    "val_dl = DataLoader(val_ds, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess(train_ds[0][0][0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CyyynR_7Asmo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Let's use 8 GPUs!\n"
     ]
    }
   ],
   "source": [
    "print('GPU disponible:' , torch.cuda.is_available())\n",
    "if torch.cuda.device_count() >= 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "KomhN9F-Fwog"
   },
   "outputs": [],
   "source": [
    "class TrainModule():\n",
    "  \n",
    "  def __init__(self, model, opt, loss_func, save_path = \"\"):\n",
    "    #self.params = params\n",
    "    self.model = model\n",
    "    self.opt = opt\n",
    "    self.loss_func = loss_func\n",
    "\n",
    "    self.fig = plt.figure(figsize=(15, 7))\n",
    "    self.ax0 = self.fig.add_subplot(1, 2, 1) \n",
    "    self.ax1 = self.fig.add_subplot(1, 2, 2)\n",
    "    \n",
    "    self.save_path = save_path\n",
    "\n",
    "    self.save_period = 10\n",
    "\n",
    "    self.visualize_period = 1\n",
    "\n",
    "  def get_data(self, train_ds, valid_ds, bs, n_cores):\n",
    "\n",
    "    self.bs = bs\n",
    "\n",
    "    self.train_dl =  DataLoader(train_ds,\n",
    "                          batch_size=bs,\n",
    "                          shuffle=True,\n",
    "                          num_workers=n_cores)\n",
    "        \n",
    "    self.val_dl =  DataLoader(valid_ds,\n",
    "                          batch_size=bs * 2,\n",
    "                          num_workers=n_cores)\n",
    "    \n",
    "  def set_optimizer(self, opt):\n",
    "    self.opt = opt\n",
    "\n",
    "  def set_loss_func(self, loss_func):\n",
    "    self.loss_func = loss_func\n",
    "  \n",
    "  def loss_batch(self, model, loss_func, xb, yb, opt=None):\n",
    "    y_hat = model(xb)\n",
    "    loss = loss_func(y_hat, yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    #accu = self.accuracy(y_hat, yb)\n",
    "\n",
    "    return loss.item(), len(xb) #, accu\n",
    "\n",
    "  def accuracy(self, y_hat_b,yb):\n",
    "    \n",
    "    preds = torch.argmax(torch.softmax(y_hat_b.view(-1), dim = 1),dim=1)\n",
    "    counts = (preds == yb)*1.0\n",
    "    \n",
    "    return torch.mean(counts)\n",
    "\n",
    "  def bin_accuracy(self, y_hat_b,yb):\n",
    "    \n",
    "    count = (yb == (y_hat_b > 0.5))*1.0\n",
    "    return torch.mean(count)\n",
    "\n",
    "  def register(self, res_list):\n",
    "    \n",
    "    losses, nums = zip(*res_list)\n",
    "    \n",
    "    N = np.sum(nums)\n",
    "    loss_mean = np.sum(np.multiply(losses, nums))/N\n",
    "    loss_std = np.sqrt(np.sum(np.multiply((losses-loss_mean)**2, nums))/(N-1))\n",
    "    \n",
    "    return loss_mean, loss_std\n",
    "\n",
    "  #def early_stoping(self, learning_data):\n",
    "\n",
    "  def plot_curves(self, loss_data, metric_data, epoch):\n",
    "      yt = loss_data['train_mean']\n",
    "      yv = loss_data['val_mean']\n",
    "      x = np.arange(0, len(yt), 1)\n",
    "      self.ax0.cla()\n",
    "      self.ax0.plot(x, yt, label='train loss')\n",
    "      self.ax0.plot(x, yv, label='val loss')\n",
    "      self.ax0.legend(loc=\"upper right\")\n",
    "      self.ax0.set_title(\"Loss at epoch: {}\".format(epoch))\n",
    "\n",
    "      ytm = metric_data['train_mean']\n",
    "      yvm = metric_data['val_mean']\n",
    "      xm = np.arange(0, len(yt), 1)\n",
    "      self.ax1.cla()\n",
    "      self.ax1.plot(xm, ytm, label='train accu')\n",
    "      self.ax1.plot(xm, yvm, label='val accu')\n",
    "      self.ax1.legend(loc=\"lower right\")\n",
    "      self.ax1.set_title(\"Accuracy at epoch: {}\".format(epoch))\n",
    "\n",
    "      display(self.fig)\n",
    "      \n",
    "      clear_output(wait = True)\n",
    "    \n",
    "  def load_learning_data(self, learning_data):\n",
    "\n",
    "    self.learning_data = learning_data\n",
    "\n",
    "  def save_checkpoint(self, model, optimizer, loss_data, metric_data,  epoch):\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #'loss': loss,\n",
    "            'loss_data': loss_data,\n",
    "            'metric_data': metric_data\n",
    "            }, self.save_path + \"checkpoint_\" + str(epoch))\n",
    "    \n",
    "  def load_model(self, model, path):\n",
    "\n",
    "    model = torch.load(path)\n",
    "\n",
    "    return model\n",
    "    \n",
    "  def save_best_model(self, model, optimizer, loss_data, metric_data, epoch):\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #'loss': loss,\n",
    "            'loss_data': loss_data,\n",
    "            'metric_data': metric_data\n",
    "            }, self.save_path + \"best_model\")\n",
    "    \n",
    "  def load_checkpoint(self, path):\n",
    "\n",
    "      checkpoint = torch.load(path)\n",
    "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "      self.opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "      epoch = checkpoint['epoch']\n",
    "      loss_data = checkpoint['loss_data']\n",
    "      metric_data = checkpoint['metric_data']\n",
    "\n",
    "      self.loss_data = loss_data\n",
    "      self.metric_data = metric_data\n",
    "\n",
    "      return epoch, loss_data, metric_data\n",
    "\n",
    "\n",
    "  def fit(self, \n",
    "        epochs,\n",
    "        metric=None,\n",
    "        only_print=True,\n",
    "        print_leap = 1):\n",
    "    \n",
    "    print('GPU disponible:' , torch.cuda.is_available())\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using \", device)\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "\n",
    "    self.model.to(device)\n",
    "    self.model = self.model.float()\n",
    "\n",
    "    print(\"Is model using cuda: \", next(self.model.parameters()).device)\n",
    "\n",
    "    if metric is None:\n",
    "        #metric = self.accuracy\n",
    "        metric= self.bin_accuracy\n",
    "        #metric = self.loss_func\n",
    "\n",
    "    loss_data = pd.DataFrame(\n",
    "        columns=['epoch', 'train_mean', 'train_std', 'val_mean', 'val_std'])\n",
    "    \n",
    "    metric_data = pd.DataFrame(\n",
    "        columns=['epoch', 'train_mean', 'train_std', 'val_mean', 'val_std'])\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        # Entrenamiento -------------------------------------------------------\n",
    "        train_res = []\n",
    "        train_metric = []\n",
    "        self.model.train()\n",
    "        for xb, yb in self.train_dl:\n",
    "            # Actualizacion de parametros\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            for i in range(len(xb)):\n",
    "                xb[:,i, :, :, :] = preproces(xb[:, i, :, :, :])\n",
    "            self.opt.zero_grad()\n",
    "            self.loss_batch(self.model, self.loss_func, xb.float(), yb.float(), self.opt)\n",
    "\n",
    "            # Evaluacion en entrenamiento\n",
    "            with torch.no_grad():\n",
    "              train_res.append(self.loss_batch(self.model, self.loss_func, xb.float(), yb.float()))\n",
    "              train_metric.append(self.loss_batch(self.model, metric, xb.float(), yb.float()))\n",
    "\n",
    "        # Validacion ----------------------------------------------------------\n",
    "        # Para evaluar se puede utilizar un metrica de rendimiento\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_res = [\n",
    "                self.loss_batch(self.model, self.loss_func, xb.to(device).float(), yb.to(device).float()) for xb, yb in self.val_dl]\n",
    "            val_metric = [\n",
    "                self.loss_batch(self.model, metric, xb.to(device).float(), yb.to(device).float()) for xb, yb in self.val_dl]\n",
    "\n",
    "        \n",
    "        val_loss0, val_std0 = self.register(val_res)\n",
    "        tra_loss0, train_std0 = self.register(train_res)\n",
    "        \n",
    "        \n",
    "        #if epoch % print_leap == 0:\n",
    "        #    print('Epoca:', epoch, '- val:', val_loss, '- train:', tra_loss)\n",
    "\n",
    "        loss_data = loss_data.append(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'train_mean': tra_loss0,\n",
    "                'train_std': train_std0,\n",
    "                'val_mean': val_loss0,\n",
    "                'val_std': val_std0\n",
    "            },\n",
    "            ignore_index=True)\n",
    "        \n",
    "        val_loss1, val_std1 = self.register(val_metric)\n",
    "        tra_loss1, train_std1 = self.register(train_metric)\n",
    "        \n",
    "        metric_data = metric_data.append(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'train_mean': tra_loss1,\n",
    "                'train_std': train_std1,\n",
    "                'val_mean': val_loss1,\n",
    "                'val_std': val_std1\n",
    "            },\n",
    "            ignore_index=True)\n",
    "        \n",
    "\n",
    "        if (epoch + 1) % self.save_period == 0:\n",
    "            #print(\"saving checkpoint at epoch \", epoch)\n",
    "            self.save_checkpoint(self.model, self.opt, loss_data, metric_data, epoch)\n",
    "\n",
    "        if epoch > epochs/10 and val_loss0 < best_val_loss:\n",
    "            #print(\"saving best model at epoch \", epoch)\n",
    "            self.save_best_model(self.model, self.opt, loss_data, metric_data, epoch)\n",
    "\n",
    "        if epoch % self.visualize_period  == 0:\n",
    "            self.plot_curves(loss_data, metric_data, epoch)\n",
    "\n",
    "    if only_print:\n",
    "        print('Proceso terminado')\n",
    "        self.loss_data = loss_data\n",
    "        self.metric_data = metric_data\n",
    "    else:\n",
    "        return loss_data, metric_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnTX7gjxebFm",
    "outputId": "1a0e09d2-1180-4d93-e0cb-5cc52bbe0fbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jupyter/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "cl_model = ExpandedCnnLSTM('resnet18', 4, 1, 512, 2, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1rrZISdrbL-B"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479,
     "referenced_widgets": [
      "87cc60e374f8491aab8820f7a9d21b64",
      "99c2d21e308d41679badbef1e4b5f250",
      "7d5281436e5a48dbb7ac8b8c6ecf4702",
      "f86bb4105c4842789fb21ec85fc26725",
      "09922f9718624ee6aa4a21ef142d045c",
      "cf40f77a28d6447bb2543d4caeb9a5d4",
      "0f87f069125b49769143dc92169052c2",
      "035f960b88af42bb9af469d8b48e3dd8"
     ]
    },
    "id": "YC4bScm9aMtL",
    "outputId": "77125aa8-b829-4a14-bfe6-8b2709646995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Using  cuda:0\n",
      "Let's use 8 GPUs!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a34e14948a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-50205de204e0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, metric, only_print, print_leap)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                         self.batch_first, bool(self.bidirectional))\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = optim.Adam(cl_model.parameters())\n",
    "\n",
    "loss_func = torch.nn.BCELoss()\n",
    "\n",
    "TM = TrainModule(cl_model, opt, loss_func)\n",
    "\n",
    "TM.get_data(train_ds, val_ds, 32, 32)\n",
    "\n",
    "TM.fit(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "abLtCEof474g",
    "outputId": "0acec351-a1d0-470a-9131-e0148d3e72e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>val_mean</th>\n",
       "      <th>val_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503561</td>\n",
       "      <td>1.038491</td>\n",
       "      <td>0.124135</td>\n",
       "      <td>0.091710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.284618</td>\n",
       "      <td>0.351057</td>\n",
       "      <td>2.569973</td>\n",
       "      <td>2.252450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.171327</td>\n",
       "      <td>0.341561</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.011023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.317469</td>\n",
       "      <td>0.756883</td>\n",
       "      <td>0.045008</td>\n",
       "      <td>0.035788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.225052</td>\n",
       "      <td>0.311097</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.008533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.087506</td>\n",
       "      <td>0.214187</td>\n",
       "      <td>0.499567</td>\n",
       "      <td>0.437961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.035111</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.001348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.000849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_mean  train_std  val_mean   val_std\n",
       "0     0.0    0.503561   1.038491  0.124135  0.091710\n",
       "1     1.0    0.284618   0.351057  2.569973  2.252450\n",
       "2     2.0    0.171327   0.341561  0.016361  0.011023\n",
       "3     3.0    0.317469   0.756883  0.045008  0.035788\n",
       "4     4.0    0.225052   0.311097  0.011560  0.008533\n",
       "5     5.0    0.087506   0.214187  0.499567  0.437961\n",
       "6     6.0    0.012449   0.035111  0.002109  0.001348\n",
       "7     7.0    0.002393   0.001265  0.001342  0.000849\n",
       "8     8.0    0.001433   0.000630  0.001038  0.000640\n",
       "9     9.0    0.001159   0.000554  0.000874  0.000546\n",
       "10   10.0    0.001021   0.000533  0.000703  0.000434\n",
       "11   11.0    0.000802   0.000376  0.000594  0.000363\n",
       "12   12.0    0.000580   0.000299  0.000510  0.000312\n",
       "13   13.0    0.000525   0.000216  0.000450  0.000273\n",
       "14   14.0    0.000543   0.000229  0.000404  0.000247\n",
       "15   15.0    0.000505   0.000236  0.000346  0.000209\n",
       "16   16.0    0.000428   0.000272  0.000307  0.000185\n",
       "17   17.0    0.000362   0.000196  0.000277  0.000167\n",
       "18   18.0    0.000333   0.000165  0.000249  0.000147\n",
       "19   19.0    0.000261   0.000147  0.000227  0.000135\n",
       "20   20.0    0.000273   0.000156  0.000210  0.000124\n",
       "21   21.0    0.000258   0.000165  0.000193  0.000114\n",
       "22   22.0    0.000238   0.000135  0.000179  0.000106\n",
       "23   23.0    0.000221   0.000127  0.000165  0.000098\n",
       "24   24.0    0.000217   0.000150  0.000153  0.000091\n",
       "25   25.0    0.000187   0.000094  0.000144  0.000085\n",
       "26   26.0    0.000188   0.000108  0.000135  0.000079\n",
       "27   27.0    0.000152   0.000079  0.000126  0.000074\n",
       "28   28.0    0.000177   0.000135  0.000760  0.000494\n",
       "29   29.0    0.000154   0.000093  0.000114  0.000068\n",
       "30   30.0    0.000124   0.000058  0.000105  0.000062\n",
       "31   31.0    0.000136   0.000065  0.000100  0.000060\n",
       "32   32.0    0.000122   0.000073  0.000097  0.000058\n",
       "33   33.0    0.000120   0.000072  0.000092  0.000055\n",
       "34   34.0    0.000107   0.000061  0.000088  0.000053\n",
       "35   35.0    0.000101   0.000060  0.000083  0.000049\n",
       "36   36.0    0.000093   0.000076  0.000079  0.000047\n",
       "37   37.0    0.000105   0.000074  0.000075  0.000044\n",
       "38   38.0    0.000097   0.000059  0.000072  0.000042\n",
       "39   39.0    0.000100   0.000049  0.000069  0.000041"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TM.load_checkpoint(\"/content/best_model\")\n",
    "\n",
    "TM.loss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCZSpTjjlI0j"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_LSTM_GCP_test.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "035f960b88af42bb9af469d8b48e3dd8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09922f9718624ee6aa4a21ef142d045c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0f87f069125b49769143dc92169052c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d5281436e5a48dbb7ac8b8c6ecf4702": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf40f77a28d6447bb2543d4caeb9a5d4",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09922f9718624ee6aa4a21ef142d045c",
      "value": 40
     }
    },
    "87cc60e374f8491aab8820f7a9d21b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d5281436e5a48dbb7ac8b8c6ecf4702",
       "IPY_MODEL_f86bb4105c4842789fb21ec85fc26725"
      ],
      "layout": "IPY_MODEL_99c2d21e308d41679badbef1e4b5f250"
     }
    },
    "99c2d21e308d41679badbef1e4b5f250": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf40f77a28d6447bb2543d4caeb9a5d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f86bb4105c4842789fb21ec85fc26725": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_035f960b88af42bb9af469d8b48e3dd8",
      "placeholder": "",
      "style": "IPY_MODEL_0f87f069125b49769143dc92169052c2",
      "value": " 40/40 [03:18&lt;00:00,  4.97s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
