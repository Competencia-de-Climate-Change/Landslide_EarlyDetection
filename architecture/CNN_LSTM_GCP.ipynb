{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W_rZdBudC-DT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import time\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kK6zkqUBKPYE"
   },
   "outputs": [],
   "source": [
    "class ExpandedCnnLSTM(nn.Module):\n",
    "  \n",
    "  def __init__(self, resnet_model, n_channels, output_size, hidden_dim, n_lstm_layers, drop_prob=0.5, debug=False):\n",
    "\n",
    "    super(ExpandedCnnLSTM, self).__init__()\n",
    "\n",
    "    self.output_size = output_size\n",
    "    self.n_lstm_layers = n_lstm_layers\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.n_channels = n_channels\n",
    "          \n",
    "    model = torch.hub.load('pytorch/vision:v0.6.0', resnet_model, pretrained=True)\n",
    "    out_channels = model.conv1.in_channels\n",
    "    kernel_size = model.conv1.kernel_size\n",
    "    stride = model.conv1.stride\n",
    "    padding = model.conv1.padding\n",
    "    self.convPadd = nn.Conv2d(n_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    \n",
    "    self.embeding_dim = model.fc.in_features\n",
    "    self.cnn = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    if debug:\n",
    "      print(model.eval())\n",
    "      print(self.cnn[0].in_channels)\n",
    "    \n",
    "\n",
    "    self.lstm = nn.LSTM(self.embeding_dim, hidden_dim, n_lstm_layers, dropout=drop_prob, batch_first=True)\n",
    "    self.dropout = nn.Dropout(drop_prob)\n",
    "    self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    n_frames = x.size(1)\n",
    "\n",
    "    features = torch.zeros((batch_size, n_frames, self.embeding_dim))\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        padded = self.convPadd(x[:,i,:])\n",
    "        features[:,i,:] = self.cnn(padded).squeeze()\n",
    "\n",
    "    lstm_out, hidden = self.lstm(features.cuda())\n",
    "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "    out = self.dropout(lstm_out)\n",
    "    out = self.fc(out)\n",
    "    out = self.sigmoid(out)\n",
    "    \n",
    "    out = out.view(batch_size, -1)\n",
    "    out = out[:,-1]\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_lstm_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_lstm_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8iEpHIEdisnS",
    "outputId": "069d1b18-c83c-4136-f936-aa940990fded"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jupyter/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#cl_model = CnnLSTM(4, 1, 512, 2)\n",
    "cl_model = ExpandedCnnLSTM('resnet18', 4, 1, 512, 2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_path = '/home/jupyter/data-step/processed_data/positive/dataset/'\n",
    "negative_path = '/home/jupyter/data-step/processed_data/negative/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_path_norm = '/home/jupyter/data-step/normalized_data/positive/dataset/'\n",
    "negative_path_norm = '/home/jupyter/data-step/normalized_data/negative/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znEhF4y2f7da",
    "outputId": "c2ee523b-b596-4a68-e94a-62a01ab89084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "1184\n"
     ]
    }
   ],
   "source": [
    "positive_files = [positive_path_norm + f for f in listdir(positive_path_norm)]\n",
    "y_p = np.ones((len(positive_files)))\n",
    "print(len(positive_files))\n",
    "\n",
    "negative_files = [negative_path_norm + f for f in listdir(negative_path_norm)]\n",
    "y_n = np.zeros((len(negative_files)))\n",
    "print(len(negative_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784 (2784,)\n"
     ]
    }
   ],
   "source": [
    "total_files = positive_files + negative_files\n",
    "\n",
    "y_tot = np.append(y_p, y_n)\n",
    "\n",
    "print(len(total_files), y_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjpqKWgw4zg5",
    "outputId": "353995cd-1ed1-40df-ad8b-6af79be5a1f7"
   },
   "outputs": [],
   "source": [
    "def channel_metrics(data):\n",
    "    n_channels = len(data[0,0, :])\n",
    "    #print(\"num channels: \", n_channels)\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for i in range(n_channels):\n",
    "            means.append(np.mean(data[:, :, i, :, :]))\n",
    "            stds.append(np.std(data[:, :, i, :, :]))\n",
    "    #print(means, stds)\n",
    "    return means, stds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def total_metrics(files):\n",
    "    means = []\n",
    "    stds = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in tqdm(files):\n",
    "        #print(count, end='\\r')\n",
    "        data = torch.load(f)\n",
    "        #print(data.shape)\n",
    "        mean, std = channel_metrics(data.numpy())\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "        count += 1\n",
    "        \n",
    "    return means, stds\n",
    "\n",
    "#means_p, stds_p = total_metrics(positive_files)\n",
    "#means_n, stds_n = total_metrics(negative_files)\n",
    "#means, stds = total_metrics(total_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#means_np = np.array(means)\n",
    "#print(means_np.shape)\n",
    "\n",
    "#stds_np = np.array(stds)\n",
    "#print(stds_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#means_np = np.append(np.array(means_p),np.array(means_n), axis=0)\n",
    "#print(means_np.shape)\n",
    "\n",
    "#stds_np = np. append(np.array(stds_p), np.array(stds_n), axis=0)\n",
    "#print(stds_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_means = np.mean(means_np, axis=0)\n",
    "#norm_stds = np.sqrt(np.sum((np.array(stds_np)**2), axis=0))/len(total_files)\n",
    "\n",
    "#print(norm_means.shape, norm_stds.shape)\n",
    "#print(norm_means, norm_stds)\n",
    "#np.save(\"/home/jupyter/means.npy\", norm_means)\n",
    "#np.save(\"/home/jupyter/stds.npy\", norm_stds)\n",
    "\n",
    "\n",
    "\n",
    "#stds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_means = torch.tensor(np.load(\"means.npy\")).float()\n",
    "norm_stds = torch.tensor(np.load(\"stds.npy\")).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "                                transforms.Normalize(mean=norm_means, std=norm_stds)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IN15Tc68XwDH"
   },
   "outputs": [],
   "source": [
    "class LandslideDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, dirs, y):\n",
    "\n",
    "        self.dirs = sorted(dirs) \n",
    "        self.l = 5#len(self.dirs)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.y)*5   # REVISAR ESTO\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.load(self.dirs[int(idx/5)])[idx%5]\n",
    "        for i in range(9):\n",
    "            for c in range(16):\n",
    "                #print(\"DL\")\n",
    "                x[i, c] = (x[i,c] - norm_means[c])/norm_stds[c]\n",
    "            #x[i] = (x[i] - norm_means) / norm_stds\n",
    "            #x[i] = preprocess(x[i].to(torch.float))\n",
    "                \n",
    "        return x, self.y[int(idx/5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SateliteDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dirs, y):\n",
    "        t = torch.tensor([])\n",
    "        for file in dirs:\n",
    "            t = torch.cat((t, torch.load(file)), 0)\n",
    "            \n",
    "        self.x = t#[torch.load(file)[j].cpu() for file in dirs for j in range(160)]\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.y)*160   # REVISAR ESTO\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "                \n",
    "        return self.x[idx], self.y[int(idx/160)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuoSateliteDataset(Dataset):\n",
    "\n",
    "    def init(self, local_dirs, mounted_dirs):\n",
    "        local_dirs         # contains train_files, train_labels\n",
    "        mounted_dirs #  contains train_files, train_labels\n",
    "        # local loading\n",
    "        t_local = torch.tensor([])\n",
    "        for file in local_dirs:\n",
    "            t_local = torch.cat((t_local, torch.load(file))[:, -3:, ...], 0)\n",
    "\n",
    "        # remote loading\n",
    "        t_remote = torch.tensor([])\n",
    "        for file in mounted_dirs:\n",
    "            tmp_tensor = torch.load(file)[:, -3:, -1, ...]\n",
    "            t_remote = torch.cat((t_remote, tmp_tensor), 0)\n",
    "\n",
    "        self.x = torch.cat((t_local, t_remote), 2) #[torch.load(file)[j].cpu() for file in dirs for j in range(160)]\n",
    "        self.y = y\n",
    "\n",
    "    def len(self): \n",
    "        return len(self.y)*160   # REVISAR ESTO\n",
    "\n",
    "    def getitem(self, idx):\n",
    "\n",
    "        return self.x[idx], self.y[int(idx/160)]\n",
    "\n",
    "\n",
    "\n",
    "def get_ds_dl(base_dir):\n",
    "  pos_sat_files= [base_dir.replace('dummy', 'positive') + x  for x in os.listdir(pos_satelite_path)]\n",
    "\n",
    "  neg_sat_files = [base_dir.replace('dummy', 'positive') + x  for x in os.listdir(neg_satelite_path)]\n",
    "\n",
    "  random.shuffle(pos_sat_files)\n",
    "  random.shuffle(neg_sat_files)\n",
    "\n",
    "  pos_cut = int(0.9len(pos_sat_files))\n",
    "  neg_cut = int(0.9*len(neg_sat_files))\n",
    "\n",
    "  train_files = pos_sat_files[:pos_cut] + neg_sat_files[:neg_cut]\n",
    "  train_labels = np.append(np.ones(pos_cut), np.zeros(neg_cut))\n",
    "\n",
    "  val_files = pos_sat_files[pos_cut:] + neg_sat_files[neg_cut:]\n",
    "  val_labels = np.append(np.ones(len(pos_sat_files) - pos_cut), np.zeros(len(neg_sat_files) - neg_cut))\n",
    "\n",
    " return [train_files, train_labels], [val_files, val_labels]\n",
    "\n",
    "\n",
    "remote_train, remote_validation = get_ds_dl( '/home/jupyter/data-step/processed_data/dummy/cfs/' )\n",
    "local_train, local_validation = get_ds_dl( '/home/jupyter/chirps/dummy/' )\n",
    "\n",
    "train_ds = DuoSateliteDataset(local_train, remote_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/data-step/normalized_data/positive/dataset/divided_part_7840_6.pt\n"
     ]
    }
   ],
   "source": [
    "#total_ds = LandslideDataset(total_files, y_tot)\n",
    "random.shuffle(positive_files)\n",
    "random.shuffle(negative_files)\n",
    "\n",
    "print(positive_files[0])\n",
    "\n",
    "pos_cut = int(0.9*len(positive_files))\n",
    "neg_cut = int(0.9*len(negative_files))\n",
    "\n",
    "train_files = positive_files[:pos_cut] + negative_files[:neg_cut]\n",
    "train_labels = np.append(np.ones(pos_cut), np.zeros(neg_cut))\n",
    "                         \n",
    "val_files = positive_files[pos_cut:] + negative_files[neg_cut:]\n",
    "val_labels = np.append(np.ones(len(positive_files) - pos_cut), np.zeros(len(negative_files) - neg_cut))\n",
    "\n",
    "# Datasets\n",
    "                         \n",
    "train_ds = LandslideDataset(train_files, train_labels)\n",
    "val_ds = LandslideDataset(val_files, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "\n",
    "train_dl = DataLoader(train_ds, num_workers=32)\n",
    "val_dl = DataLoader(val_ds, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "pos_satelite_path = '/home/jupyter/chirps/positive/'\n",
    "#print(listdir(pos_satelite_path))\n",
    "pos_sat_files = [pos_satelite_path + x  for x in listdir(pos_satelite_path)]\n",
    "print(len(pos_sat_files))\n",
    "\n",
    "neg_satelite_path = '/home/jupyter/chirps/negative/'\n",
    "#print(listdir(pos_satelite_path))\n",
    "neg_sat_files = [neg_satelite_path + x  for x in listdir(neg_satelite_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/chirps/positive/chirps5120.pt\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(pos_sat_files)\n",
    "random.shuffle(neg_sat_files)\n",
    "\n",
    "print(pos_sat_files[0])\n",
    "\n",
    "pos_cut = int(0.9*len(pos_sat_files))\n",
    "neg_cut = int(0.9*len(neg_sat_files))\n",
    "\n",
    "train_files = pos_sat_files[:pos_cut] + neg_sat_files[:neg_cut]\n",
    "train_labels = np.append(np.ones(pos_cut), np.zeros(neg_cut))\n",
    "                         \n",
    "val_files = pos_sat_files[pos_cut:] + neg_sat_files[neg_cut:]\n",
    "val_labels = np.append(np.ones(len(pos_sat_files) - pos_cut), np.zeros(len(neg_sat_files) - neg_cut))\n",
    "\n",
    "# Datasets\n",
    "                         \n",
    "train_sat_ds = SateliteDataset(train_files, train_labels)\n",
    "val_sat_ds = SateliteDataset(val_files, val_labels)\n",
    "\n",
    "train_sat_dl = DataLoader(train_sat_ds, num_workers=1)\n",
    "val_sat_dl = DataLoader(val_sat_ds, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1, 224, 224])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sat_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess(train_ds[0][0][0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyyynR_7Asmo"
   },
   "outputs": [],
   "source": [
    "print('GPU disponible:' , torch.cuda.is_available())\n",
    "if torch.cuda.device_count() >= 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "KomhN9F-Fwog"
   },
   "outputs": [],
   "source": [
    "class TrainModule():\n",
    "  \n",
    "  def __init__(self, model, opt, loss_func, save_path = \"\"):\n",
    "    #self.params = params\n",
    "    self.model = model\n",
    "    self.opt = opt\n",
    "    self.loss_func = loss_func\n",
    "\n",
    "    self.fig = plt.figure(figsize=(15, 7))\n",
    "    self.ax0 = self.fig.add_subplot(1, 2, 1) \n",
    "    self.ax1 = self.fig.add_subplot(1, 2, 2)\n",
    "    \n",
    "    self.save_path = save_path\n",
    "\n",
    "    self.save_period = 1\n",
    "\n",
    "    self.visualize_period = 1\n",
    "\n",
    "  def get_data(self, train_ds, valid_ds, bs, n_cores):\n",
    "\n",
    "    self.bs = bs\n",
    "\n",
    "    self.train_dl =  DataLoader(train_ds,\n",
    "                          batch_size=bs,\n",
    "                          shuffle=True,\n",
    "                          num_workers=n_cores)\n",
    "        \n",
    "    self.val_dl =  DataLoader(valid_ds,\n",
    "                          batch_size=bs * 2,\n",
    "                          num_workers=n_cores)\n",
    "    \n",
    "  def set_optimizer(self, opt):\n",
    "    self.opt = opt\n",
    "\n",
    "  def set_loss_func(self, loss_func):\n",
    "    self.loss_func = loss_func\n",
    "  \n",
    "  def loss_batch(self, model, loss_func, xb, yb, opt=None):\n",
    "    y_hat = model(xb)\n",
    "    loss = loss_func(y_hat, yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    #accu = self.accuracy(y_hat, yb)\n",
    "\n",
    "    return loss.item(), len(xb) #, accu\n",
    "\n",
    "  def accuracy(self, y_hat_b,yb):\n",
    "    \n",
    "    preds = torch.argmax(torch.softmax(y_hat_b.view(-1), dim = 1),dim=1)\n",
    "    counts = (preds == yb)*1.0\n",
    "    \n",
    "    return torch.mean(counts)\n",
    "\n",
    "  def bin_accuracy(self, y_hat_b,yb):\n",
    "    \n",
    "    count = (yb == (y_hat_b > 0.5))*1.0\n",
    "    return torch.mean(count)\n",
    "\n",
    "  def register(self, res_list):\n",
    "    \n",
    "    losses, nums = zip(*res_list)\n",
    "    \n",
    "    N = np.sum(nums)\n",
    "    loss_mean = np.sum(np.multiply(losses, nums))/N\n",
    "    loss_std = np.sqrt(np.sum(np.multiply((losses-loss_mean)**2, nums))/(N-1))\n",
    "    \n",
    "    return loss_mean, loss_std\n",
    "\n",
    "  #def early_stoping(self, learning_data):\n",
    "\n",
    "  def plot_curves(self, loss_data, metric_data, epoch):\n",
    "      yt = loss_data['train_mean']\n",
    "      yv = loss_data['val_mean']\n",
    "      x = np.arange(0, len(yt), 1)\n",
    "      self.ax0.cla()\n",
    "      self.ax0.plot(x, yt, label='train loss')\n",
    "      self.ax0.plot(x, yv, label='val loss')\n",
    "      self.ax0.legend(loc=\"upper right\")\n",
    "      self.ax0.set_title(\"Loss at epoch: {}\".format(epoch))\n",
    "\n",
    "      ytm = metric_data['train_mean']\n",
    "      yvm = metric_data['val_mean']\n",
    "      xm = np.arange(0, len(yt), 1)\n",
    "      self.ax1.cla()\n",
    "      self.ax1.plot(xm, ytm, label='train accu')\n",
    "      self.ax1.plot(xm, yvm, label='val accu')\n",
    "      self.ax1.legend(loc=\"lower right\")\n",
    "      self.ax1.set_title(\"Accuracy at epoch: {}\".format(epoch))\n",
    "\n",
    "      display(self.fig)\n",
    "      \n",
    "      clear_output(wait = True)\n",
    "    \n",
    "  def load_learning_data(self, learning_data):\n",
    "\n",
    "    self.learning_data = learning_data\n",
    "\n",
    "  def save_checkpoint(self, model, optimizer, loss_data, metric_data,  epoch):\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #'loss': loss,\n",
    "            'loss_data': loss_data,\n",
    "            'metric_data': metric_data\n",
    "            }, self.save_path + \"checkpoint_\" + str(epoch))\n",
    "    \n",
    "  def load_model(self, model, path):\n",
    "\n",
    "    model = torch.load(path)\n",
    "\n",
    "    return model\n",
    "    \n",
    "  def save_best_model(self, model, optimizer, loss_data, metric_data, epoch):\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #'loss': loss,\n",
    "            'loss_data': loss_data,\n",
    "            'metric_data': metric_data\n",
    "            }, self.save_path + \"best_model\")\n",
    "    \n",
    "  def load_checkpoint(self, path):\n",
    "\n",
    "      checkpoint = torch.load(path)\n",
    "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "      self.opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "      epoch = checkpoint['epoch']\n",
    "      loss_data = checkpoint['loss_data']\n",
    "      metric_data = checkpoint['metric_data']\n",
    "\n",
    "      self.loss_data = loss_data\n",
    "      self.metric_data = metric_data\n",
    "\n",
    "      return epoch, loss_data, metric_data\n",
    "\n",
    "\n",
    "  def fit(self, \n",
    "        epochs,\n",
    "        metric=None,\n",
    "        only_print=True,\n",
    "        print_leap = 1):\n",
    "    \n",
    "    print('GPU disponible:' , torch.cuda.is_available())\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using \", device)\n",
    "    \n",
    "    self.model = self.model.float()\n",
    "    self.model.cuda()\n",
    "    \n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "\n",
    "    #\n",
    "    \n",
    "\n",
    "    print(\"Is model using cuda: \", next(self.model.parameters()).device)\n",
    "\n",
    "    if metric is None:\n",
    "        #metric = self.accuracy\n",
    "        metric= self.bin_accuracy\n",
    "        #metric = self.loss_func\n",
    "\n",
    "    loss_data = pd.DataFrame(\n",
    "        columns=['epoch', 'train_mean', 'train_std', 'val_mean', 'val_std'])\n",
    "    \n",
    "    metric_data = pd.DataFrame(\n",
    "        columns=['epoch', 'train_mean', 'train_std', 'val_mean', 'val_std'])\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    print(\"Start\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        # Entrenamiento -------------------------------------------------------\n",
    "        train_res = []\n",
    "        train_metric = []\n",
    "        self.model.train()\n",
    "        for xb, yb in tqdm(self.train_dl):\n",
    "            #print(\"Aqui\")\n",
    "            # Actualizacion de parametros\n",
    "            xb, yb = xb.cuda(), yb.cuda()\n",
    "            #for i in range(len(xb)):\n",
    "            #    xb[:,i, :, :, :] = preproces(xb[:, i, :, :, :])\n",
    "            self.opt.zero_grad()\n",
    "            self.loss_batch(self.model, self.loss_func, xb.float(), yb.float(), self.opt)\n",
    "\n",
    "            # Evaluacion en entrenamiento\n",
    "            with torch.no_grad():\n",
    "              train_res.append(self.loss_batch(self.model, self.loss_func, xb.float(), yb.float()))\n",
    "              train_metric.append(self.loss_batch(self.model, metric, xb.float(), yb.float()))\n",
    "\n",
    "        # Validacion ----------------------------------------------------------\n",
    "        # Para evaluar se puede utilizar un metrica de rendimiento\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_res = [\n",
    "                self.loss_batch(self.model, self.loss_func, xb.cuda().float(), yb.cuda().float()) for xb, yb in self.val_dl]\n",
    "            val_metric = [\n",
    "                self.loss_batch(self.model, metric, xb.cuda().float(), yb.cuda().float()) for xb, yb in self.val_dl]\n",
    "\n",
    "        \n",
    "        val_loss0, val_std0 = self.register(val_res)\n",
    "        tra_loss0, train_std0 = self.register(train_res)\n",
    "        \n",
    "        \n",
    "        #if epoch % print_leap == 0:\n",
    "        #    print('Epoca:', epoch, '- val:', val_loss, '- train:', tra_loss)\n",
    "\n",
    "        loss_data = loss_data.append(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'train_mean': tra_loss0,\n",
    "                'train_std': train_std0,\n",
    "                'val_mean': val_loss0,\n",
    "                'val_std': val_std0\n",
    "            },\n",
    "            ignore_index=True)\n",
    "        \n",
    "        val_loss1, val_std1 = self.register(val_metric)\n",
    "        tra_loss1, train_std1 = self.register(train_metric)\n",
    "        \n",
    "        metric_data = metric_data.append(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'train_mean': tra_loss1,\n",
    "                'train_std': train_std1,\n",
    "                'val_mean': val_loss1,\n",
    "                'val_std': val_std1\n",
    "            },\n",
    "            ignore_index=True)\n",
    "        \n",
    "\n",
    "        if (epoch + 1) % self.save_period == 0:\n",
    "            #print(\"saving checkpoint at epoch \", epoch)\n",
    "            self.save_checkpoint(self.model, self.opt, loss_data, metric_data, epoch)\n",
    "\n",
    "        if epoch > epochs/epochs and val_loss0 < best_val_loss:\n",
    "            #print(\"saving best model at epoch \", epoch)\n",
    "            self.save_best_model(self.model, self.opt, loss_data, metric_data, epoch)\n",
    "\n",
    "        if epoch % self.visualize_period  == 0:\n",
    "            self.plot_curves(loss_data, metric_data, epoch)\n",
    "\n",
    "    if only_print:\n",
    "        print('Proceso terminado')\n",
    "        self.loss_data = loss_data\n",
    "        self.metric_data = metric_data\n",
    "    else:\n",
    "        return loss_data, metric_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnTX7gjxebFm",
    "outputId": "1a0e09d2-1180-4d93-e0cb-5cc52bbe0fbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jupyter/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "cl_model = ExpandedCnnLSTM('resnet18', 1, 1, 512, 2, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1rrZISdrbL-B"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479,
     "referenced_widgets": [
      "87cc60e374f8491aab8820f7a9d21b64",
      "99c2d21e308d41679badbef1e4b5f250",
      "7d5281436e5a48dbb7ac8b8c6ecf4702",
      "f86bb4105c4842789fb21ec85fc26725",
      "09922f9718624ee6aa4a21ef142d045c",
      "cf40f77a28d6447bb2543d4caeb9a5d4",
      "0f87f069125b49769143dc92169052c2",
      "035f960b88af42bb9af469d8b48e3dd8"
     ]
    },
    "id": "YC4bScm9aMtL",
    "outputId": "77125aa8-b829-4a14-bfe6-8b2709646995"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:186: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c77f91ed85433dad7da06873ce9241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:574: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:1276.)\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(cl_model.parameters())\n",
    "\n",
    "loss_func = torch.nn.BCELoss()\n",
    "\n",
    "TM = TrainModule(cl_model, opt, loss_func)\n",
    "\n",
    "TM.get_data(train_sat_ds, val_sat_ds, 128, 1)\n",
    "\n",
    "TM.fit(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "abLtCEof474g",
    "outputId": "0acec351-a1d0-470a-9131-e0148d3e72e1"
   },
   "outputs": [],
   "source": [
    "TM.load_checkpoint(\"/content/best_model\")\n",
    "\n",
    "TM.loss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCZSpTjjlI0j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_LSTM_GCP_test.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "035f960b88af42bb9af469d8b48e3dd8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09922f9718624ee6aa4a21ef142d045c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0f87f069125b49769143dc92169052c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d5281436e5a48dbb7ac8b8c6ecf4702": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf40f77a28d6447bb2543d4caeb9a5d4",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09922f9718624ee6aa4a21ef142d045c",
      "value": 40
     }
    },
    "87cc60e374f8491aab8820f7a9d21b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d5281436e5a48dbb7ac8b8c6ecf4702",
       "IPY_MODEL_f86bb4105c4842789fb21ec85fc26725"
      ],
      "layout": "IPY_MODEL_99c2d21e308d41679badbef1e4b5f250"
     }
    },
    "99c2d21e308d41679badbef1e4b5f250": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf40f77a28d6447bb2543d4caeb9a5d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f86bb4105c4842789fb21ec85fc26725": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_035f960b88af42bb9af469d8b48e3dd8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0f87f069125b49769143dc92169052c2",
      "value": " 40/40 [03:18&lt;00:00,  4.97s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
