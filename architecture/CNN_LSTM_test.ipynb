{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_LSTM_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3a202760d1e46b996fd5e15026c83f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d5435d875eb64ed1bf1426c35fba464e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a9797e712da46cda5cbb78b38765fdd",
              "IPY_MODEL_be695fbabb0f426086b54af604783bb9"
            ]
          }
        },
        "d5435d875eb64ed1bf1426c35fba464e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a9797e712da46cda5cbb78b38765fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb11728368b4485e901f0eef3730152f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c7514f2bda2443f9d4fe39a580a9305"
          }
        },
        "be695fbabb0f426086b54af604783bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8973828282e43089a3efd31285d3cc1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [06:12&lt;00:00, 126kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_402b931c9729416a89ed37d12106de23"
          }
        },
        "eb11728368b4485e901f0eef3730152f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c7514f2bda2443f9d4fe39a580a9305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8973828282e43089a3efd31285d3cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "402b931c9729416a89ed37d12106de23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK_XI7H3C-DN"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# ResNet\n",
        "\n",
        "*Author: Pytorch Team*\n",
        "\n",
        "**Deep residual networks pre-trained on ImageNet**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/resnet.png\" alt=\"alt\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_rZdBudC-DT",
        "outputId": "eb2058f3-4452-4c00-d1f7-9ae36c6b820c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d3a202760d1e46b996fd5e15026c83f7",
            "d5435d875eb64ed1bf1426c35fba464e",
            "6a9797e712da46cda5cbb78b38765fdd",
            "be695fbabb0f426086b54af604783bb9",
            "eb11728368b4485e901f0eef3730152f",
            "7c7514f2bda2443f9d4fe39a580a9305",
            "b8973828282e43089a3efd31285d3cc1",
            "402b931c9729416a89ed37d12106de23"
          ]
        }
      },
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet152', pretrained=True)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3a202760d1e46b996fd5e15026c83f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw7JDVQuwAop",
        "outputId": "94fc73df-8a76-4ff6-ca80-b847566195d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.conv1.in_channels = 4\n",
        "model.conv1.in_channels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV3pMmz8C-Dc"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "Here's a sample execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3JqEDFyC-Dd"
      },
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a18oeA2MC-Dl",
        "outputId": "aa9608ed-bde6-4878-885a-895fe357c1c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "print(torch.nn.functional.softmax(output[0], dim=0))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1.5916e-02, -1.5497e+00,  3.2030e-01, -2.0585e+00, -8.5747e-01,\n",
            "         1.7843e+00,  1.4699e+00,  2.1626e+00,  4.4888e+00,  8.2885e-01,\n",
            "        -5.7819e+00, -3.4969e+00, -4.0621e+00, -4.7517e+00, -3.8072e+00,\n",
            "        -4.7243e+00, -1.2590e+00,  2.9813e-01, -2.0459e+00, -5.2885e-01,\n",
            "        -3.5982e+00, -8.1424e-01, -2.7651e+00, -1.2770e+00, -3.4182e+00,\n",
            "        -1.9048e+00, -3.0018e+00, -1.3471e+00, -1.8391e+00,  1.3937e+00,\n",
            "        -2.0114e+00, -1.4137e+00, -2.3287e+00, -1.8198e+00, -1.1914e-01,\n",
            "        -3.4102e+00, -1.6544e+00, -3.4496e+00, -2.6479e+00, -2.7407e+00,\n",
            "        -2.2193e+00, -3.6509e+00, -4.1255e+00, -5.5946e+00, -1.7519e+00,\n",
            "        -1.6900e+00, -9.8164e-01, -2.1251e+00, -3.5137e+00, -1.3320e+00,\n",
            "        -1.1335e+00, -1.1564e+00, -2.2711e-02, -8.5797e-01, -1.2919e+00,\n",
            "        -2.8682e+00,  6.6078e-01, -1.7178e+00, -1.2443e+00, -2.3362e+00,\n",
            "        -5.7816e-02, -1.9204e+00, -2.5964e+00, -1.8020e+00, -1.5125e+00,\n",
            "        -1.0843e+00, -4.0987e-01, -1.3090e+00, -9.4153e-01, -4.0615e+00,\n",
            "        -1.9027e+00, -6.0975e-01, -2.3426e+00, -2.5544e+00, -2.7568e+00,\n",
            "        -2.1587e+00, -3.0438e+00, -3.8201e+00,  1.9932e+00,  8.0768e-01,\n",
            "        -2.8857e+00, -4.6229e-01, -1.9095e+00, -1.8599e+00, -1.9991e-01,\n",
            "        -7.4706e-01, -2.3904e+00, -1.1250e+00, -2.0491e+00,  2.2938e+00,\n",
            "        -2.6377e+00, -3.6704e+00, -4.7520e+00, -2.8039e+00, -1.9299e+00,\n",
            "        -4.6468e+00, -2.5182e+00, -2.4850e+00, -3.0077e+00, -4.8836e-01,\n",
            "        -9.3521e-01, -2.6058e+00,  2.1376e+00, -2.6329e+00,  8.3506e+00,\n",
            "         8.9667e-01,  3.7531e+00, -3.4335e+00, -1.8960e+00, -4.2943e+00,\n",
            "         2.9082e-01, -2.3308e+00,  2.3836e+00,  4.2319e-02,  2.2397e-01,\n",
            "         7.5308e-01, -3.3080e+00, -1.4768e+00, -1.1792e+00, -1.9249e+00,\n",
            "        -1.8421e+00, -1.2775e+00, -1.0864e+00, -9.9565e-01,  1.5227e-01,\n",
            "        -1.4355e+00, -1.8052e+00,  1.0732e+00, -1.8634e+00,  2.6153e-01,\n",
            "        -1.5023e+00, -4.6530e+00, -1.9521e+00, -6.8744e+00, -1.6433e+00,\n",
            "        -3.2272e+00, -3.2739e+00, -3.8374e+00, -2.1751e+00, -3.5047e+00,\n",
            "        -4.7009e+00, -3.6270e+00, -4.8844e+00, -1.9901e+00,  2.6526e-01,\n",
            "        -6.7295e-01,  9.3509e-01, -2.2415e+00, -2.1363e+00, -4.7924e-01,\n",
            "        -2.6271e-01,  5.0756e+00,  4.4932e+00,  5.3031e+00,  5.1180e+00,\n",
            "         1.0446e+00,  5.5505e-02,  5.7181e+00,  2.8040e+00, -6.5414e-01,\n",
            "         7.1562e-01, -1.0806e+00, -8.4479e-01, -1.4036e+00, -4.8315e-01,\n",
            "        -4.0582e+00,  2.1610e-02, -1.7137e+00, -2.5360e-01,  5.0012e+00,\n",
            "         6.5730e+00,  3.8631e-01,  1.3999e-01,  3.1344e+00,  6.6824e+00,\n",
            "         2.2414e+00,  4.6645e-01,  3.2950e+00, -8.5229e-01,  1.1061e+00,\n",
            "         1.6826e+00,  2.9594e-02,  2.7676e+00,  1.0094e+00,  3.2906e+00,\n",
            "         6.0673e+00,  7.0697e+00,  5.1815e-01,  3.6306e+00,  2.7650e+00,\n",
            "         3.2205e+00, -9.3784e-01,  6.9483e+00,  4.2839e+00,  2.6159e+00,\n",
            "         1.6080e+00,  4.3847e-01,  1.0887e+00, -3.5319e-01,  6.1558e+00,\n",
            "         2.6472e+00,  1.6073e+00,  2.6772e+00,  1.0351e+01,  2.5268e+00,\n",
            "         8.3448e-01, -1.3505e+00,  5.1928e+00,  2.9642e+00, -5.6726e-01,\n",
            "        -1.4320e+00,  2.9363e-02,  2.4520e+00,  3.0417e-01, -7.7818e-01,\n",
            "         1.6603e+00,  1.9853e+00,  2.0598e+00,  2.6966e-01, -1.8801e-01,\n",
            "         2.7371e-01, -1.7507e+00,  8.8910e+00,  8.1109e+00,  7.3231e+00,\n",
            "         2.8657e+00,  3.7826e+00,  4.1981e+00,  5.8150e+00,  6.1472e+00,\n",
            "         6.4172e+00,  7.6086e+00,  6.9847e+00,  2.9936e+00, -5.2758e-01,\n",
            "         5.5965e+00,  1.4392e+00, -3.9503e-01,  2.0425e+00,  1.8702e+00,\n",
            "         2.0413e+00,  2.0422e-01,  6.4460e-01, -4.0614e-01,  2.5661e+00,\n",
            "         1.2417e+00,  1.4611e+00,  4.1676e+00,  1.0818e+01,  8.7367e+00,\n",
            "         9.9064e+00,  2.8385e+00,  2.0287e-01,  1.7976e+00,  2.3186e+00,\n",
            "         2.5285e+00,  4.5001e+00,  1.1026e+01,  1.6273e+01,  1.1215e+01,\n",
            "         7.8094e+00,  1.0740e+01, -9.9221e-02,  5.7142e+00,  4.7237e+00,\n",
            "         3.3941e+00,  3.0939e+00,  3.8398e+00, -8.0394e-01,  8.1740e+00,\n",
            "         1.3279e+01,  3.4679e+00,  4.4451e+00,  5.5244e+00,  4.1509e+00,\n",
            "        -1.9328e-01,  1.3198e+00,  5.0951e+00,  4.9228e+00,  1.3313e+01,\n",
            "         4.6688e+00,  4.1280e+00,  3.8479e+00,  6.4162e+00,  6.1095e+00,\n",
            "         3.3097e+00,  2.3572e+00,  6.8445e+00,  9.5434e-01,  2.8592e+00,\n",
            "        -1.1244e+00,  1.5085e+00,  1.7631e+00,  1.2531e+00,  2.8554e+00,\n",
            "         1.7463e+00,  6.7799e+00,  2.5124e-01, -1.3342e+00,  5.1050e-01,\n",
            "        -2.8969e+00, -8.2496e-01, -2.9130e+00, -3.0456e+00, -1.1142e+00,\n",
            "        -2.8026e+00, -1.4486e+00, -6.7262e-01, -4.2247e+00, -1.7623e+00,\n",
            "         4.3570e-01, -1.4014e+00, -1.5380e+00, -1.5596e+00,  1.6334e+00,\n",
            "        -2.3892e+00, -2.9759e+00, -4.3734e-01, -5.5001e-01, -6.1542e+00,\n",
            "        -4.0857e+00, -2.3556e+00, -3.9536e+00, -2.8767e+00, -4.4984e-01,\n",
            "        -1.7370e+00, -1.6374e+00,  2.1360e+00, -8.5107e-01, -1.5193e-02,\n",
            "         2.7704e+00,  5.3773e+00,  5.9535e+00,  5.4208e+00,  2.8854e+00,\n",
            "         3.7443e-01,  1.6293e+00,  4.4487e-01,  3.2411e+00,  9.7582e-01,\n",
            "         2.5312e-02,  3.1032e+00, -2.7100e-01, -2.7836e+00, -3.1692e+00,\n",
            "         8.1342e-01, -6.5196e-01, -2.9631e+00,  2.6037e+00, -9.6922e-01,\n",
            "        -9.5742e-01, -4.7068e+00, -3.5804e+00,  2.2840e-01, -2.1702e+00,\n",
            "         6.5002e+00,  5.7219e+00,  2.9793e+00,  6.4611e+00,  5.4975e+00,\n",
            "        -5.2996e-01,  4.7048e+00,  2.8008e+00, -3.6088e-03, -1.3491e+00,\n",
            "        -4.5432e-01, -5.6187e-01, -1.6322e+00,  2.1284e+00, -1.4569e+00,\n",
            "        -1.1633e-03,  9.0620e-01,  1.6597e+00,  2.0624e+00,  1.0829e+00,\n",
            "        -8.1911e-01, -3.6819e+00,  2.5470e+00,  1.4180e+00,  5.3964e-01,\n",
            "         1.0845e+00, -9.6097e-02,  4.6213e-01,  1.0754e+00,  7.6537e-02,\n",
            "        -2.6620e+00, -4.3084e+00,  3.6672e+00,  5.1774e+00, -6.1791e-01,\n",
            "        -1.5415e+00,  7.3573e-01, -3.7433e+00, -2.9970e+00, -5.4823e-01,\n",
            "        -1.9205e+00, -3.7729e+00, -2.9885e+00, -9.2415e-01, -4.2514e-01,\n",
            "        -8.8965e-01, -5.8486e-01, -6.5334e-01, -4.9157e+00, -2.8375e+00,\n",
            "         3.4268e-01, -2.2503e+00, -2.7347e-01, -2.4050e+00, -5.2626e-01,\n",
            "        -2.6042e+00,  3.2445e-01,  4.0667e+00, -2.1196e+00, -5.1543e-01,\n",
            "        -1.7745e+00, -2.0623e+00, -6.6496e-01, -1.4364e+00,  9.8571e-01,\n",
            "         5.9969e-03, -9.6792e-01, -6.0225e-01, -1.4000e+00, -2.0710e+00,\n",
            "         1.1075e+00, -1.9486e+00,  2.2065e+00,  2.9293e+00,  1.8658e+00,\n",
            "        -2.8881e+00, -4.3115e-01, -1.3990e+00, -3.7418e-01,  7.7501e-01,\n",
            "         3.9198e+00, -7.5727e-01, -1.8530e-01, -1.6255e+00,  2.2081e+00,\n",
            "         1.5956e+00,  6.9976e-02,  3.9040e-01,  4.6344e-01,  5.9016e-01,\n",
            "        -9.2833e-02, -5.1500e-01, -1.3637e+00, -1.5078e-01, -5.6912e-01,\n",
            "         2.4666e+00, -1.7132e+00, -1.6860e+00, -3.2602e-01, -8.4201e-01,\n",
            "         2.1154e+00, -8.4043e-02,  1.7860e+00, -6.3439e-01, -7.4765e-01,\n",
            "         4.2897e-01, -5.1184e-01,  3.4125e+00,  5.7139e+00, -1.2795e+00,\n",
            "        -1.6497e+00, -2.5285e+00, -3.1734e+00, -1.0102e+00,  9.4759e-01,\n",
            "         9.9308e-01, -1.0922e-01,  2.5839e+00,  1.4922e+00, -1.2992e+00,\n",
            "        -2.8170e-01, -8.6435e-01, -1.4672e-01,  1.7313e+00,  2.4510e+00,\n",
            "        -7.3570e-01, -2.5554e+00, -1.9142e+00,  1.6980e-01,  3.2633e-01,\n",
            "        -1.3443e+00, -1.5297e+00, -7.6557e-01, -7.8684e-01,  1.0074e+00,\n",
            "        -1.2130e+00,  1.4810e+00, -2.7207e-01, -1.3605e+00, -1.7983e-01,\n",
            "        -1.1730e+00,  2.3959e+00, -6.8000e-01, -2.6903e+00,  7.7480e-02,\n",
            "        -3.4509e+00,  1.2124e+00,  1.2672e+00, -1.0999e+00,  2.8032e-01,\n",
            "        -9.9974e-01, -2.0026e+00,  7.5466e-01,  2.4307e+00, -1.7246e+00,\n",
            "        -7.9768e-02,  8.8518e-01, -4.0756e-01, -2.4663e+00, -1.2027e+00,\n",
            "         5.4814e-01, -1.6021e+00, -2.4280e+00,  5.5574e-01, -3.8049e-01,\n",
            "        -2.0516e+00,  3.3770e+00,  3.1902e+00,  6.7000e-01, -6.8531e-01,\n",
            "        -9.4827e-01, -3.6431e-01, -7.6097e-01,  2.1828e+00,  8.0118e-01,\n",
            "        -1.0046e+00, -1.2824e+00, -2.3656e+00, -3.1687e+00,  2.1272e+00,\n",
            "         1.2672e-01, -1.6892e+00,  2.6973e+00, -3.0822e+00,  4.0324e+00,\n",
            "        -2.8332e+00,  3.3901e-01,  1.0079e-02,  5.2546e-01,  1.9752e+00,\n",
            "        -7.1670e-02,  2.9041e-01, -2.9111e+00, -2.4014e+00,  7.0131e-01,\n",
            "        -4.1842e+00,  4.7369e-01,  1.1472e+00, -6.1524e-01, -7.0896e-01,\n",
            "        -3.9984e-01, -3.3715e-01, -6.5772e-01, -2.2189e+00,  1.5345e+00,\n",
            "         1.2745e+00,  2.7751e-01, -2.2735e+00, -5.5896e-01, -3.7202e+00,\n",
            "        -2.9080e+00, -6.8846e-01,  9.7099e-02,  1.8661e+00, -8.5187e-01,\n",
            "        -8.4573e-01, -3.8525e+00,  3.4325e-01,  2.5432e-01,  2.6882e+00,\n",
            "         2.5991e-01, -2.0000e+00,  5.3708e-01,  1.0960e+00, -1.3279e+00,\n",
            "         1.4837e+00, -5.9335e-01, -2.0439e+00, -1.2370e+00,  1.0513e+00,\n",
            "         6.4954e-01, -6.2646e-02,  1.2370e+00,  6.8368e-01,  3.8259e+00,\n",
            "        -1.7971e+00, -6.7278e-01, -2.5600e+00, -1.6512e+00,  1.1806e+00,\n",
            "        -1.2924e+00,  2.2586e+00, -4.0487e-01, -1.1882e+00, -2.3765e+00,\n",
            "         7.9954e-01, -9.1990e-01, -1.6126e+00, -1.9355e+00, -3.9238e+00,\n",
            "        -2.1017e+00,  2.1352e+00, -2.5646e-01,  4.8958e-01, -6.0499e-01,\n",
            "         1.1564e+00,  1.8465e+00, -4.0932e+00,  2.7047e-01, -2.1523e-01,\n",
            "         1.3753e+00, -1.4033e+00, -1.0388e+00,  4.7859e-02, -1.2730e-01,\n",
            "         3.2859e-01,  1.8630e+00,  3.2699e+00, -3.5367e-01, -2.1416e+00,\n",
            "        -4.3182e-01,  7.7666e-01,  3.7311e-02, -2.0635e+00,  3.1160e-01,\n",
            "         1.6417e+00,  2.6682e+00,  2.7170e-01,  8.3577e-01, -2.9818e+00,\n",
            "        -2.4503e-01,  2.4742e-01,  1.3297e-01, -4.3417e-01, -4.3046e-01,\n",
            "         6.5773e-01,  2.1311e+00, -3.2655e+00, -5.1050e-01,  4.9344e-01,\n",
            "        -1.8940e+00,  1.8291e+00, -1.6717e+00,  6.3228e-01, -1.6439e+00,\n",
            "        -1.6570e+00, -1.1182e-03, -6.8659e-01,  2.0163e+00, -4.9133e-01,\n",
            "         7.9273e-01, -6.5997e-01, -1.4483e+00,  5.7451e-01,  2.2929e-01,\n",
            "        -3.0037e-01, -2.0797e+00, -9.1574e-01, -1.9492e+00,  8.3745e-01,\n",
            "         1.2692e+00, -9.1458e-01,  5.4567e-01, -3.6889e+00, -9.1367e-01,\n",
            "         1.9861e+00, -2.5311e-01,  2.8521e-01,  2.0949e+00,  1.2086e+00,\n",
            "         2.1154e-01,  3.4622e+00,  9.5277e-02, -8.0216e-01,  2.7265e-01,\n",
            "         1.2197e+00,  7.2029e-01, -2.8354e+00, -2.7143e+00,  4.7934e-01,\n",
            "        -1.8512e+00,  2.9761e-01, -4.1026e+00,  1.8250e-01, -7.9936e-01,\n",
            "        -1.7338e+00, -9.6721e-01, -5.8128e-01, -8.2822e-01, -9.8596e-02,\n",
            "        -5.0435e-01,  1.5544e+00,  1.4904e+00, -1.2979e+00, -1.0826e-01,\n",
            "         2.9883e+00, -1.3630e+00, -3.7239e+00,  9.1957e-01, -2.5768e+00,\n",
            "        -3.0649e+00,  1.3365e+00, -1.4009e+00, -3.5322e-01, -1.1704e+00,\n",
            "        -7.4978e-01, -2.5903e-01, -6.0259e-01, -1.5579e+00,  1.3899e+00,\n",
            "        -2.3793e+00,  1.9803e+00,  3.3006e-01, -1.0206e-01,  2.4416e+00,\n",
            "         1.2657e+00, -6.6137e-01,  2.2869e+00,  1.8482e+00, -2.9063e+00,\n",
            "        -5.7494e-01, -5.1072e+00, -2.6364e+00,  2.1372e+00, -1.3472e+00,\n",
            "        -2.2591e+00,  4.3973e+00, -2.2593e+00, -1.0246e+00, -3.2030e+00,\n",
            "         6.7143e-01, -1.9926e+00, -2.0654e-01,  4.0617e-01, -2.9339e+00,\n",
            "         1.5753e+00, -9.1893e-01,  1.1542e+00, -9.1348e-01, -1.2591e+00,\n",
            "        -1.9500e+00,  1.0347e+00,  8.3912e-01,  1.6410e+00,  1.3352e+00,\n",
            "         7.9203e-01,  7.8801e-01,  1.2226e+00,  1.3795e+00, -7.8040e-01,\n",
            "        -1.3666e+00,  5.3833e+00,  5.1338e-01,  4.9046e-01,  5.2560e-01,\n",
            "         7.3350e-01,  2.2732e+00, -1.3203e+00,  9.3211e-01, -1.6302e+00,\n",
            "         2.4191e-01, -2.4870e-01, -4.8620e-01,  2.1138e+00,  1.4489e+00,\n",
            "         3.7366e-01,  1.4004e+00,  1.5152e+00, -3.6104e-01,  2.9181e-01,\n",
            "        -9.4115e-01, -2.2436e+00, -4.9276e-01, -4.5846e-01, -2.1174e+00,\n",
            "        -2.6535e+00, -4.2171e-01,  1.4914e+00,  6.6903e-01,  1.0808e+00,\n",
            "        -2.9792e-01,  1.3667e+00,  7.1145e-01,  2.7972e-01,  3.5889e-02,\n",
            "        -1.5736e+00,  6.9128e-01,  1.3083e+00, -6.9339e-01,  8.5358e-02,\n",
            "        -4.8842e-01, -1.4164e+00,  2.3650e+00, -8.0813e-01,  7.6430e-01,\n",
            "        -4.9398e+00, -6.1574e-01, -4.6486e-01, -2.4251e+00,  1.1547e+00,\n",
            "         6.3762e+00,  9.0707e-01, -4.1598e-01, -1.3366e+00,  2.3717e-01,\n",
            "         1.4613e+00,  2.6384e+00, -1.3068e+00,  8.5315e-01, -3.5892e-01,\n",
            "        -9.9009e-01, -1.2835e+00,  5.5976e-01,  2.0848e-02, -8.9666e-01,\n",
            "        -6.9400e-01, -1.9417e+00, -6.7528e-01,  1.2534e+00,  1.3382e+00,\n",
            "         8.7609e-01, -4.7604e-01,  1.7552e+00,  5.1028e-01, -1.3920e+00,\n",
            "        -8.7654e-01,  1.1599e+00, -1.0186e+00, -1.3284e+00, -3.7166e-01,\n",
            "        -1.0469e+00,  5.7449e-01,  1.5574e+00,  1.8519e+00, -4.1095e-01,\n",
            "        -2.0581e-01,  1.0532e+00,  1.8591e+00,  4.5595e-01,  9.1578e-01,\n",
            "         1.1539e+00, -1.4320e+00, -5.3197e-01, -1.4754e+00, -1.0053e+00,\n",
            "         1.2264e+00,  1.5214e+00,  5.0184e+00, -1.5203e+00, -5.4168e-01,\n",
            "        -6.5428e-01, -1.8736e+00, -3.6343e+00, -1.0429e+00,  7.0413e-02,\n",
            "        -2.3703e+00,  2.4605e+00, -1.3011e-01, -1.7982e+00, -7.5531e-01,\n",
            "        -1.0359e+00, -1.3380e+00, -2.9617e-01, -8.2643e-01,  2.7119e-01,\n",
            "         1.5884e+00, -7.2461e-01, -2.9711e-01, -9.3042e-01, -2.4289e+00,\n",
            "        -9.2284e-01,  4.7528e+00, -1.6790e+00,  8.6679e-01,  7.8210e-01,\n",
            "         1.6629e+00, -1.0685e+00,  1.3574e+00, -8.2428e-01, -1.9540e+00,\n",
            "         4.4793e-01, -2.2733e+00, -1.9748e+00, -1.3135e+00,  7.5049e-02,\n",
            "        -6.2613e-01, -1.2929e+00, -7.9226e-01,  1.4181e-01, -5.3668e-01,\n",
            "        -3.7515e+00,  2.5790e+00,  2.9517e+00,  1.1170e+00, -7.2467e-02,\n",
            "        -1.0601e+00,  1.7500e-01,  1.4925e+00, -1.3864e+00,  1.2885e+00,\n",
            "        -1.8532e+00, -2.2471e+00,  2.7472e-01, -2.0507e+00, -5.4335e-01,\n",
            "         8.9407e-01,  7.9924e-01,  1.3935e+00, -1.7301e-01, -5.9534e-01,\n",
            "         8.0483e-01, -1.3372e-01, -3.2294e+00, -2.1450e-01, -1.5620e+00,\n",
            "        -2.2868e+00, -3.0804e-01, -4.4390e+00, -6.2412e-01, -2.5382e+00,\n",
            "        -2.4722e+00, -3.3123e+00, -2.8575e+00, -2.9189e+00,  3.9108e+00,\n",
            "        -2.2020e+00, -2.0254e+00, -5.1858e-01, -4.8108e+00, -2.6819e+00,\n",
            "         7.0437e-01, -3.2433e-01,  8.4757e-01,  1.2196e+00,  1.4949e+00,\n",
            "        -1.9164e+00, -3.8725e+00, -4.3444e-01,  2.0204e+00, -2.2128e+00,\n",
            "        -3.7765e+00, -3.2417e+00, -1.0154e+00,  1.8904e+00,  4.7872e-01,\n",
            "        -2.6042e+00, -2.1485e+00, -2.8178e+00, -1.2955e+00, -1.0276e+00,\n",
            "        -2.7621e+00, -1.6165e+00, -4.1204e-01, -1.9367e-01, -2.4879e+00,\n",
            "        -1.3851e+00,  7.6086e-01, -2.6262e+00, -2.1398e+00, -5.1703e+00,\n",
            "        -2.3795e+00, -4.5068e-01, -4.3725e+00, -2.3892e-01, -8.7407e-01,\n",
            "         4.7021e-01,  1.5145e+00, -1.1402e+00, -3.5778e+00, -1.3159e-01,\n",
            "         2.2065e+00, -1.6685e+00,  7.5954e-01, -1.0781e+00, -7.7719e-01,\n",
            "        -6.3171e-01,  1.1631e-01,  1.1369e+00, -1.4187e+00, -8.3358e-01,\n",
            "        -1.6156e+00, -2.2305e+00,  6.9370e-01, -3.4886e+00, -1.4845e+00,\n",
            "        -1.3031e+00, -1.8285e-01, -5.2394e-01, -5.7335e+00, -1.8339e+00,\n",
            "        -6.5607e-01, -1.8088e+00, -2.9126e+00,  5.6032e-01,  2.5117e+00])\n",
            "tensor([7.6953e-08, 1.6081e-08, 1.0433e-07, 9.6677e-09, 3.2131e-08, 4.5105e-07,\n",
            "        3.2936e-07, 6.5847e-07, 6.7416e-06, 1.7349e-07, 2.3350e-10, 2.2942e-09,\n",
            "        1.3037e-09, 6.5414e-10, 1.6821e-09, 6.7232e-10, 2.1504e-08, 1.0204e-07,\n",
            "        9.7905e-09, 4.4631e-08, 2.0732e-09, 3.3550e-08, 4.7693e-09, 2.1121e-08,\n",
            "        2.4821e-09, 1.1274e-08, 3.7641e-09, 1.9692e-08, 1.2039e-08, 3.0521e-07,\n",
            "        1.0134e-08, 1.8423e-08, 7.3789e-09, 1.2275e-08, 6.7231e-08, 2.5019e-09,\n",
            "        1.4481e-08, 2.4052e-09, 5.3622e-09, 4.8868e-09, 8.2314e-09, 1.9667e-09,\n",
            "        1.2236e-09, 2.8159e-10, 1.3136e-08, 1.3975e-08, 2.8379e-08, 9.0448e-09,\n",
            "        2.2559e-09, 1.9992e-08, 2.4380e-08, 2.3829e-08, 7.4037e-08, 3.2115e-08,\n",
            "        2.0809e-08, 4.3020e-09, 1.4665e-07, 1.3592e-08, 2.1823e-08, 7.3232e-09,\n",
            "        7.1483e-08, 1.1099e-08, 5.6456e-09, 1.2495e-08, 1.6690e-08, 2.5611e-08,\n",
            "        5.0270e-08, 2.0456e-08, 2.9540e-08, 1.3045e-09, 1.1298e-08, 4.1163e-08,\n",
            "        7.2768e-09, 5.8878e-09, 4.8088e-09, 8.7459e-09, 3.6093e-09, 1.6606e-09,\n",
            "        5.5583e-07, 1.6986e-07, 4.2273e-09, 4.7703e-08, 1.1221e-08, 1.1791e-08,\n",
            "        6.2015e-08, 3.5881e-08, 6.9369e-09, 2.4590e-08, 9.7592e-09, 7.5076e-07,\n",
            "        5.4170e-09, 1.9288e-09, 6.5394e-10, 4.5878e-09, 1.0995e-08, 7.2649e-10,\n",
            "        6.1047e-09, 6.3109e-09, 3.7417e-09, 4.6475e-08, 2.9727e-08, 5.5929e-09,\n",
            "        6.4218e-07, 5.4434e-09, 3.2057e-04, 1.8567e-07, 3.2304e-06, 2.4443e-09,\n",
            "        1.1373e-08, 1.0335e-09, 1.0130e-07, 7.3634e-09, 8.2131e-07, 7.9012e-08,\n",
            "        9.4751e-08, 1.6083e-07, 2.7711e-09, 1.7296e-08, 2.3292e-08, 1.1049e-08,\n",
            "        1.2003e-08, 2.1110e-08, 2.5556e-08, 2.7984e-08, 8.8195e-08, 1.8025e-08,\n",
            "        1.2454e-08, 2.2151e-07, 1.1750e-08, 9.8377e-08, 1.6861e-08, 7.2198e-10,\n",
            "        1.0752e-08, 7.8304e-11, 1.4643e-08, 3.0045e-09, 2.8674e-09, 1.6322e-09,\n",
            "        8.6032e-09, 2.2764e-09, 6.8825e-10, 2.0143e-09, 5.7286e-10, 1.0352e-08,\n",
            "        9.8744e-08, 3.8642e-08, 1.9294e-07, 8.0511e-09, 8.9438e-09, 4.6901e-08,\n",
            "        5.8240e-08, 1.2124e-05, 6.7713e-06, 1.5220e-05, 1.2648e-05, 2.1528e-07,\n",
            "        8.0060e-08, 2.3050e-05, 1.2505e-06, 3.9375e-08, 1.5492e-07, 2.5704e-08,\n",
            "        3.2540e-08, 1.8609e-08, 4.6718e-08, 1.3088e-09, 7.7392e-08, 1.3648e-08,\n",
            "        5.8773e-08, 1.1254e-05, 5.4192e-05, 1.1145e-07, 8.7118e-08, 1.7401e-06,\n",
            "        6.0454e-05, 7.1243e-07, 1.2075e-07, 2.0431e-06, 3.2297e-08, 2.2893e-07,\n",
            "        4.0745e-07, 7.8013e-08, 1.2057e-06, 2.0782e-07, 2.0343e-06, 3.2683e-05,\n",
            "        8.9056e-05, 1.2716e-07, 2.8581e-06, 1.2026e-06, 1.8966e-06, 2.9649e-08,\n",
            "        7.8875e-05, 5.4927e-06, 1.0361e-06, 3.7813e-07, 1.1742e-07, 2.2497e-07,\n",
            "        5.3202e-08, 3.5706e-05, 1.0690e-06, 3.7790e-07, 1.1016e-06, 2.3704e-03,\n",
            "        9.4771e-07, 1.7447e-07, 1.9624e-08, 1.3630e-05, 1.4677e-06, 4.2949e-08,\n",
            "        1.8088e-08, 7.7995e-08, 8.7945e-07, 1.0266e-07, 3.4782e-08, 3.9846e-07,\n",
            "        5.5148e-07, 5.9411e-07, 9.9180e-08, 6.2757e-08, 9.9583e-08, 1.3152e-08,\n",
            "        5.5033e-04, 2.5226e-04, 1.1473e-04, 1.3300e-06, 3.3273e-06, 5.0412e-06,\n",
            "        2.5395e-05, 3.5401e-05, 4.6372e-05, 1.5265e-04, 8.1800e-05, 1.5115e-06,\n",
            "        4.4688e-08, 2.0411e-05, 3.1942e-07, 5.1022e-08, 5.8395e-07, 4.9148e-07,\n",
            "        5.8321e-07, 9.2897e-08, 1.4430e-07, 5.0458e-08, 9.8571e-07, 2.6215e-07,\n",
            "        3.2650e-07, 4.8896e-06, 3.7817e-03, 4.7163e-04, 1.5191e-03, 1.2944e-06,\n",
            "        9.2772e-08, 4.5708e-07, 7.6959e-07, 9.4933e-07, 6.8182e-06, 4.6520e-03,\n",
            "        8.8462e-01, 5.6214e-03, 1.8660e-04, 3.4972e-03, 6.8584e-08, 2.2959e-05,\n",
            "        8.5272e-06, 2.2560e-06, 1.6710e-06, 3.5232e-06, 3.3897e-08, 2.6867e-04,\n",
            "        4.4276e-02, 2.4288e-06, 6.4532e-06, 1.8991e-05, 4.8086e-06, 6.2427e-08,\n",
            "        2.8345e-07, 1.2362e-05, 1.0406e-05, 4.5805e-02, 8.0717e-06, 4.6999e-06,\n",
            "        3.5515e-06, 4.6326e-05, 3.4092e-05, 2.0735e-06, 7.9991e-07, 7.1097e-05,\n",
            "        1.9669e-07, 1.3215e-06, 2.4603e-08, 3.4234e-07, 4.4160e-07, 2.6518e-07,\n",
            "        1.3164e-06, 4.3421e-07, 6.6649e-05, 9.7370e-08, 1.9948e-08, 1.2619e-07,\n",
            "        4.1801e-09, 3.3192e-08, 4.1135e-09, 3.6025e-09, 2.4855e-08, 4.5934e-09,\n",
            "        1.7791e-08, 3.8654e-08, 1.1080e-09, 1.3000e-08, 1.1709e-07, 1.8651e-08,\n",
            "        1.6270e-08, 1.5922e-08, 3.8787e-07, 6.9451e-09, 3.8629e-09, 4.8908e-08,\n",
            "        4.3696e-08, 1.6092e-10, 1.2733e-09, 7.1831e-09, 1.4531e-09, 4.2657e-09,\n",
            "        4.8300e-08, 1.3334e-08, 1.4730e-08, 6.4117e-07, 3.2337e-08, 7.4596e-08,\n",
            "        1.2091e-06, 1.6392e-05, 2.9166e-05, 1.7121e-05, 1.3565e-06, 1.1013e-07,\n",
            "        3.8627e-07, 1.1817e-07, 1.9361e-06, 2.0096e-07, 7.7679e-08, 1.6867e-06,\n",
            "        5.7759e-08, 4.6816e-09, 3.1838e-09, 1.7084e-07, 3.9461e-08, 3.9123e-09,\n",
            "        1.0235e-06, 2.8733e-08, 2.9074e-08, 6.8419e-10, 2.1105e-09, 9.5172e-08,\n",
            "        8.6461e-09, 5.0386e-05, 2.3136e-05, 1.4900e-06, 4.8457e-05, 1.8486e-05,\n",
            "        4.4582e-08, 8.3669e-06, 1.2465e-06, 7.5465e-08, 1.9653e-08, 4.8084e-08,\n",
            "        4.3181e-08, 1.4807e-08, 6.3628e-07, 1.7643e-08, 7.5650e-08, 1.8744e-07,\n",
            "        3.9823e-07, 5.9566e-07, 2.2366e-07, 3.3387e-08, 1.9067e-09, 9.6708e-07,\n",
            "        3.1272e-07, 1.2992e-07, 2.2404e-07, 6.8798e-08, 1.2023e-07, 2.2199e-07,\n",
            "        8.1762e-08, 5.2872e-09, 1.0190e-09, 2.9646e-06, 1.3422e-05, 4.0828e-08,\n",
            "        1.6212e-08, 1.5807e-07, 1.7932e-09, 3.7821e-09, 4.3774e-08, 1.1098e-08,\n",
            "        1.7408e-09, 3.8144e-09, 3.0058e-08, 4.9508e-08, 3.1113e-08, 4.2200e-08,\n",
            "        3.9407e-08, 5.5520e-10, 4.4359e-09, 1.0669e-07, 7.9805e-09, 5.7616e-08,\n",
            "        6.8366e-09, 4.4747e-08, 5.6016e-09, 1.0477e-07, 4.4204e-06, 9.0948e-09,\n",
            "        4.5234e-08, 1.2843e-08, 9.6312e-09, 3.8952e-08, 1.8009e-08, 2.0296e-07,\n",
            "        7.6193e-08, 2.8771e-08, 4.1472e-08, 1.8678e-08, 9.5472e-09, 2.2923e-07,\n",
            "        1.0790e-08, 6.8799e-07, 1.4175e-06, 4.8934e-07, 4.2173e-09, 4.9212e-08,\n",
            "        1.8696e-08, 5.2096e-08, 1.6440e-07, 3.8163e-06, 3.5517e-08, 6.2927e-08,\n",
            "        1.4907e-08, 6.8912e-07, 3.7347e-07, 8.1228e-08, 1.1191e-07, 1.2039e-07,\n",
            "        1.3665e-07, 6.9023e-08, 4.5253e-08, 1.9367e-08, 6.5137e-08, 4.2869e-08,\n",
            "        8.9238e-07, 1.3655e-08, 1.4030e-08, 5.4667e-08, 3.2631e-08, 6.2811e-07,\n",
            "        6.9633e-08, 4.5184e-07, 4.0161e-08, 3.5860e-08, 1.1631e-07, 4.5397e-08,\n",
            "        2.2979e-06, 2.2952e-05, 2.1068e-08, 1.4549e-08, 6.0422e-09, 3.1703e-09,\n",
            "        2.7580e-08, 1.9537e-07, 2.0446e-07, 6.7901e-08, 1.0035e-06, 3.3681e-07,\n",
            "        2.0658e-08, 5.7144e-08, 3.1910e-08, 6.5402e-08, 4.2775e-07, 8.7859e-07,\n",
            "        3.6291e-08, 5.8817e-09, 1.1169e-08, 8.9755e-08, 1.0496e-07, 1.9747e-08,\n",
            "        1.6404e-08, 3.5223e-08, 3.4482e-08, 2.0741e-07, 2.2517e-08, 3.3305e-07,\n",
            "        5.7697e-08, 1.9429e-08, 6.3272e-08, 2.3436e-08, 8.3142e-07, 3.8370e-08,\n",
            "        5.1397e-09, 8.1839e-08, 2.4021e-09, 2.5460e-07, 2.6895e-07, 2.5213e-08,\n",
            "        1.0024e-07, 2.7870e-08, 1.0223e-08, 1.6109e-07, 8.6089e-07, 1.3499e-08,\n",
            "        6.9931e-08, 1.8355e-07, 5.0386e-08, 6.4303e-09, 2.2750e-08, 1.3103e-07,\n",
            "        1.5259e-08, 6.6811e-09, 1.3203e-07, 5.1769e-08, 9.7350e-09, 2.2177e-06,\n",
            "        1.8400e-06, 1.4801e-07, 3.8167e-08, 2.9342e-08, 5.2613e-08, 3.5386e-08,\n",
            "        6.7187e-07, 1.6876e-07, 2.7736e-08, 2.1007e-08, 7.1110e-09, 3.1855e-09,\n",
            "        6.3554e-07, 8.5970e-08, 1.3986e-08, 1.1239e-06, 3.4731e-09, 4.2715e-06,\n",
            "        4.4552e-09, 1.0630e-07, 7.6505e-08, 1.2809e-07, 5.4594e-07, 7.0500e-08,\n",
            "        1.0126e-07, 4.1211e-09, 6.8612e-09, 1.5272e-07, 1.1538e-09, 1.2163e-07,\n",
            "        2.3853e-07, 4.0937e-08, 3.7275e-08, 5.0776e-08, 5.4062e-08, 3.9235e-08,\n",
            "        8.2351e-09, 3.5136e-07, 2.7092e-07, 9.9962e-08, 7.7972e-09, 4.3307e-08,\n",
            "        1.8350e-09, 4.1342e-09, 3.8047e-08, 8.3461e-08, 4.8952e-07, 3.2311e-08,\n",
            "        3.2510e-08, 1.6076e-09, 1.0675e-07, 9.7671e-08, 1.1137e-06, 9.8218e-08,\n",
            "        1.0250e-08, 1.2959e-07, 2.2663e-07, 2.0074e-08, 3.3393e-07, 4.1843e-08,\n",
            "        9.8102e-09, 2.1982e-08, 2.1672e-07, 1.4501e-07, 7.1139e-08, 2.6094e-07,\n",
            "        1.5005e-07, 3.4744e-06, 1.2556e-08, 3.8648e-08, 5.8550e-09, 1.4528e-08,\n",
            "        2.4663e-07, 2.0798e-08, 7.2481e-07, 5.0522e-08, 2.3083e-08, 7.0341e-09,\n",
            "        1.6848e-07, 3.0186e-08, 1.5100e-08, 1.0933e-08, 1.4971e-09, 9.2588e-09,\n",
            "        6.4064e-07, 5.8605e-08, 1.2358e-07, 4.1359e-08, 2.4072e-07, 4.7998e-07,\n",
            "        1.2637e-09, 9.9261e-08, 6.1072e-08, 2.9964e-07, 1.8615e-08, 2.6801e-08,\n",
            "        7.9451e-08, 6.6685e-08, 1.0520e-07, 4.8797e-07, 1.9925e-06, 5.3176e-08,\n",
            "        8.8971e-09, 4.9178e-08, 1.6467e-07, 7.8617e-08, 9.6198e-09, 1.0343e-07,\n",
            "        3.9110e-07, 1.0916e-06, 9.9383e-08, 1.7470e-07, 3.8399e-09, 5.9279e-08,\n",
            "        9.6999e-08, 8.6509e-08, 4.9063e-08, 4.9246e-08, 1.4621e-07, 6.3802e-07,\n",
            "        2.8914e-09, 4.5458e-08, 1.2405e-07, 1.1396e-08, 4.7170e-07, 1.4233e-08,\n",
            "        1.4253e-07, 1.4634e-08, 1.4444e-08, 7.5653e-08, 3.8118e-08, 5.6882e-07,\n",
            "        4.6338e-08, 1.6734e-07, 3.9146e-08, 1.7795e-08, 1.3453e-07, 9.5256e-08,\n",
            "        5.6087e-08, 9.4643e-09, 3.0312e-08, 1.0784e-08, 1.7499e-07, 2.6947e-07,\n",
            "        3.0347e-08, 1.3071e-07, 1.8935e-09, 3.0375e-08, 5.5188e-07, 5.8801e-08,\n",
            "        1.0073e-07, 6.1532e-07, 2.5362e-07, 9.3580e-08, 2.4150e-06, 8.3309e-08,\n",
            "        3.3958e-08, 9.9477e-08, 2.5645e-07, 1.5564e-07, 4.4456e-09, 5.0178e-09,\n",
            "        1.2232e-07, 1.1894e-08, 1.0199e-07, 1.2519e-09, 9.0901e-08, 3.4053e-08,\n",
            "        1.3376e-08, 2.8791e-08, 4.2351e-08, 3.3084e-08, 6.8627e-08, 4.5738e-08,\n",
            "        3.5843e-07, 3.3618e-07, 2.0683e-08, 6.7966e-08, 1.5036e-06, 1.9381e-08,\n",
            "        1.8284e-09, 1.8997e-07, 5.7573e-09, 3.5337e-09, 2.8825e-07, 1.8660e-08,\n",
            "        5.3200e-08, 2.3497e-08, 3.5784e-08, 5.8454e-08, 4.1458e-08, 1.5949e-08,\n",
            "        3.0405e-07, 7.0148e-09, 5.4874e-07, 1.0536e-07, 6.8389e-08, 8.7035e-07,\n",
            "        2.6855e-07, 3.9092e-08, 7.4557e-07, 4.8079e-07, 4.1413e-09, 4.2621e-08,\n",
            "        4.5845e-10, 5.4242e-09, 6.4190e-07, 1.9688e-08, 7.9103e-09, 6.1521e-06,\n",
            "        7.9087e-09, 2.7185e-08, 3.0780e-09, 1.4822e-07, 1.0326e-08, 6.1605e-08,\n",
            "        1.1369e-07, 4.0285e-09, 3.6599e-07, 3.0215e-08, 2.4021e-07, 3.0380e-08,\n",
            "        2.1503e-08, 1.0775e-08, 2.1315e-07, 1.7528e-07, 3.9085e-07, 2.8787e-07,\n",
            "        1.6722e-07, 1.6655e-07, 2.5720e-07, 3.0091e-07, 3.4705e-08, 1.9312e-08,\n",
            "        1.6492e-05, 1.2655e-07, 1.2369e-07, 1.2811e-07, 1.5771e-07, 7.3542e-07,\n",
            "        2.0226e-08, 1.9236e-07, 1.4837e-08, 9.6465e-08, 5.9061e-08, 4.6576e-08,\n",
            "        6.2708e-07, 3.2251e-07, 1.1005e-07, 3.0725e-07, 3.4464e-07, 5.2785e-08,\n",
            "        1.0140e-07, 2.9551e-08, 8.0341e-09, 4.6271e-08, 4.7886e-08, 9.1143e-09,\n",
            "        5.3321e-09, 4.9679e-08, 3.3653e-07, 1.4787e-07, 2.2319e-07, 5.6225e-08,\n",
            "        2.9708e-07, 1.5427e-07, 1.0018e-07, 7.8505e-08, 1.5701e-08, 1.5119e-07,\n",
            "        2.8023e-07, 3.7860e-08, 8.2487e-08, 4.6472e-08, 1.8373e-08, 8.0613e-07,\n",
            "        3.3756e-08, 1.6265e-07, 5.4199e-10, 4.0917e-08, 4.7580e-08, 6.7008e-09,\n",
            "        2.4033e-07, 4.4512e-05, 1.8761e-07, 4.9964e-08, 1.9899e-08, 9.6009e-08,\n",
            "        3.2654e-07, 1.0596e-06, 2.0500e-08, 1.7776e-07, 5.2897e-08, 2.8140e-08,\n",
            "        2.0984e-08, 1.3256e-07, 7.7333e-08, 3.0896e-08, 3.7836e-08, 1.0866e-08,\n",
            "        3.8552e-08, 2.6524e-07, 2.8872e-07, 1.8188e-07, 4.7051e-08, 4.3812e-07,\n",
            "        1.2616e-07, 1.8826e-08, 3.1524e-08, 2.4157e-07, 2.7348e-08, 2.0062e-08,\n",
            "        5.2228e-08, 2.6586e-08, 1.3453e-07, 3.5947e-07, 4.8260e-07, 5.0215e-08,\n",
            "        6.1649e-08, 2.1713e-07, 4.8608e-07, 1.1949e-07, 1.8925e-07, 2.4013e-07,\n",
            "        1.8088e-08, 4.4492e-08, 1.7320e-08, 2.7715e-08, 2.5820e-07, 3.4678e-07,\n",
            "        1.1449e-05, 1.6560e-08, 4.4062e-08, 3.9370e-08, 1.1630e-08, 1.9997e-09,\n",
            "        2.6693e-08, 8.1263e-08, 7.0777e-09, 8.8692e-07, 6.6498e-08, 1.2542e-08,\n",
            "        3.5587e-08, 2.6881e-08, 1.9872e-08, 5.6323e-08, 3.3143e-08, 9.9332e-08,\n",
            "        3.7081e-07, 3.6696e-08, 5.6270e-08, 2.9870e-08, 6.6750e-09, 3.0097e-08,\n",
            "        8.7787e-06, 1.4130e-08, 1.8020e-07, 1.6557e-07, 3.9950e-07, 2.6017e-08,\n",
            "        2.9431e-07, 3.3215e-08, 1.0733e-08, 1.1854e-07, 7.7990e-09, 1.0511e-08,\n",
            "        2.0364e-08, 8.1641e-08, 4.0494e-08, 2.0787e-08, 3.4296e-08, 8.7277e-08,\n",
            "        4.4283e-08, 1.7786e-09, 9.9850e-07, 1.4496e-06, 2.3144e-07, 7.0444e-08,\n",
            "        2.6236e-08, 9.0222e-08, 3.3691e-07, 1.8932e-08, 2.7472e-07, 1.1871e-08,\n",
            "        8.0061e-09, 9.9684e-08, 9.7433e-09, 4.3989e-08, 1.8518e-07, 1.6843e-07,\n",
            "        3.0515e-07, 6.3706e-08, 4.1760e-08, 1.6937e-07, 6.6258e-08, 2.9977e-09,\n",
            "        6.1116e-08, 1.5883e-08, 7.6941e-09, 5.5659e-08, 8.9432e-10, 4.0575e-08,\n",
            "        5.9841e-09, 6.3923e-09, 2.7594e-09, 4.3483e-09, 4.0895e-09, 3.7822e-06,\n",
            "        8.3753e-09, 9.9926e-09, 4.5092e-08, 6.1664e-10, 5.1831e-09, 1.5319e-07,\n",
            "        5.4759e-08, 1.7677e-07, 2.5643e-07, 3.3771e-07, 1.1144e-08, 1.5758e-09,\n",
            "        4.9050e-08, 5.7115e-07, 8.2850e-09, 1.7347e-09, 2.9611e-09, 2.7437e-08,\n",
            "        5.0154e-07, 1.2224e-07, 5.6019e-09, 8.8353e-09, 4.5242e-09, 2.0733e-08,\n",
            "        2.7105e-08, 4.7836e-09, 1.5041e-08, 5.0161e-08, 6.2403e-08, 6.2929e-09,\n",
            "        1.8957e-08, 1.6209e-07, 5.4797e-09, 8.9129e-09, 4.3040e-10, 7.0131e-09,\n",
            "        4.8260e-08, 9.5581e-10, 5.9642e-08, 3.1602e-08, 1.2121e-07, 3.4439e-07,\n",
            "        2.4218e-08, 2.1158e-09, 6.6399e-08, 6.8796e-07, 1.4279e-08, 1.6187e-07,\n",
            "        2.5770e-08, 3.4816e-08, 4.0268e-08, 8.5080e-08, 2.3608e-07, 1.8331e-08,\n",
            "        3.2907e-08, 1.5054e-08, 8.1401e-09, 1.5156e-07, 2.3134e-09, 1.7163e-08,\n",
            "        2.0577e-08, 6.3081e-08, 4.4851e-08, 2.4506e-10, 1.2102e-08, 3.9299e-08,\n",
            "        1.2410e-08, 4.1151e-09, 1.3263e-07, 9.3353e-07])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybz9FjF9C-Dq"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "Resnet models were proposed in \"Deep Residual Learning for Image Recognition\".\n",
        "Here we have the 5 versions of resnet models, which contains 5, 34, 50, 101, 152 layers respectively.\n",
        "Detailed model architectures can be found in Table 1.\n",
        "Their 1-crop error rates on imagenet dataset with pretrained models are listed below.\n",
        "\n",
        "| Model structure | Top-1 error | Top-5 error |\n",
        "| --------------- | ----------- | ----------- |\n",
        "|  resnet18       | 30.24       | 10.92       |\n",
        "|  resnet34       | 26.70       | 8.58        |\n",
        "|  resnet50       | 23.85       | 7.13        |\n",
        "|  resnet101      | 22.63       | 6.44        |\n",
        "|  resnet152      | 21.69       | 5.94        |\n",
        "\n",
        "### References\n",
        "\n",
        " - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUo7V9cn4fpU"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0yDiBpg4XmI"
      },
      "source": [
        "class CnnLSTM(nn.Module):\n",
        "  \n",
        "  def __init__(self, n_channels, output_size, hidden_dim, n_lstm_layers, drop_prob=0.5):\n",
        "\n",
        "    super(CnnLSTM, self).__init__()\n",
        "\n",
        "    self.output_size = output_size\n",
        "    self.n_lstm_layers = n_lstm_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_channels = n_channels\n",
        "          \n",
        "    model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
        "    out_channels = model.conv1.out_channels\n",
        "    kernel_size = model.conv1.kernel_size\n",
        "    stride = model.conv1.stride\n",
        "    padding = model.conv1.padding\n",
        "    model.conv1 = nn.Conv2d(n_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "    print(model.eval())\n",
        "    self.embeding_dim = model.fc.in_features\n",
        "    self.cnn = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "    print(self.cnn[0].in_channels)\n",
        "    \n",
        "\n",
        "    self.lstm = nn.LSTM(self.embeding_dim, hidden_dim, n_lstm_layers, dropout=drop_prob, batch_first=True)\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    n_frames = x.size(1)\n",
        "\n",
        "    features = torch.zeros((batch_size, n_frames, self.embeding_dim))\n",
        "\n",
        "    for i in range(n_frames):\n",
        "      features[:,i,:] = self.cnn(x[:,i,:]).squeeze()\n",
        "\n",
        "    lstm_out, hidden = self.lstm(features, hidden)\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "    out = self.dropout(lstm_out)\n",
        "    out = self.fc(out)\n",
        "    out = self.sigmoid(out)\n",
        "    \n",
        "    out = out.view(batch_size, -1)\n",
        "    out = out[:,-1]\n",
        "    \n",
        "    return out, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_lstm_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_lstm_layers, batch_size, self.hidden_dim).zero_())\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iEpHIEdisnS",
        "outputId": "a64c09a1-b55e-4dda-85cf-4b60573d55df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cl_model = CnnLSTM(4, 1, 512, 2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaoK_1svtaRx",
        "outputId": "f849e6e6-92ff-401f-ca12-8b5feeb82867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cl_model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of CnnLSTM(\n",
              "  (cnn): Sequential(\n",
              "    (0): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (lstm): LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ceqmqPpCka",
        "outputId": "1a604992-3a34-4c0e-c1b1-20e9c642170b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "test_batch = torch.randn((6, 13, 4, 256, 256))\n",
        "hidden = cl_model.init_hidden(test_batch.size(0))\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    test_batch = test_batch.to('cuda')\n",
        "    cl_model.to('cuda')\n",
        "    hidden = hidden.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = cl_model(test_batch, hidden)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "print(torch.nn.functional.softmax(output[0], dim=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4878, 0.5108, 0.4770, 0.4946, 0.4919, 0.4865])\n",
            "tensor([0.1661, 0.1699, 0.1643, 0.1672, 0.1667, 0.1658])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOlSb2k0r6sp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}